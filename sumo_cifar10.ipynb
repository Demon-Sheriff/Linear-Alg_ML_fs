{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5GEDBZuEwSDQyX+nTri3q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Demon-Sheriff/Linear-Alg_ML_fs/blob/master/sumo_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb"
      ],
      "metadata": {
        "id": "tOFNHXPopS-V"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (a:=3*4) > 1/8 * (b:=5*6):\n",
        "  print(\"ok\")\n",
        "print(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaPDX8pHqWXU",
        "outputId": "6c1e6f9d-80a8-4dba-ab12-8231a4d04381"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ok\n",
            "12 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u,sig,v = torch.linalg.svd(torch.randn(4, 3), full_matrices=False)\n",
        "u.shape, sig.shape, v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW6PhlPsFsEk",
        "outputId": "502f0144-48bd-41aa-ab6f-75304016fd94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 3]), torch.Size([3]), torch.Size([3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# u.shape, sig.shape, v.shape\n",
        "# mxm, rxr, nxn\n",
        "# sig = torch.eye(v.size(0))\n",
        "# (u @ sig).shape\n",
        "\"\"\"\n",
        "1 0 0 0\n",
        "0 1 0 0\n",
        "0 0 1 0\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vlxUawBBFzzH",
        "outputId": "23158401-7712-4c03-a735-03892efe1214"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1 0 0 0\\n0 1 0 0\\n0 0 1 0\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u,sig,v = torch.svd_lowrank(torch.randn(4, 1), q=3)\n",
        "u.shape, sig.shape, v.shape\n",
        "# torch.zeros(3,4)\n",
        "# i think i know where this is going wrong : what about the case when r > min(m, n) which is happening in the case of (4, 1) param in the TinyNet model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7VAAw8DaqDO",
        "outputId": "8283f2e3-c027-4351-e4e0-fcc16008155b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4, 1]), torch.Size([1]), torch.Size([1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.eye(1).shape\n",
        "torch.zeros(1, 4).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbqeBCy8F9UI",
        "outputId": "3f916fc4-1c5e-48bd-b404-7a8e093023fa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.autograd.set_detect_anomaly(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgnPBMDP9HCg",
        "outputId": "f106cf87-fdb4-4f6a-a469-9a36f63444de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x783add660f50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.compile\n",
        "def orthogonalization_svd(M):\n",
        "    # Fix: Use M.float() to prevent FP16 instability\n",
        "    U, sig, Vh = torch.linalg.svd(M.float(), full_matrices=False)\n",
        "    # Fix: PyTorch returns Vh (V conjugate transpose), so O = U @ Vh is correct\n",
        "    return U @ Vh\n",
        "\n",
        "class SUMO(torch.optim.Optimizer):\n",
        "    def __init__(self, params, step_size=1e-4, scale_factor=2.0, weight_decay=0.01,\n",
        "                 rank=8, K=200, step_clip_ratio=1.1, momentum_coeff=0.9):\n",
        "        defaults = dict(step_size=step_size, scale_factor=scale_factor, weight_decay=weight_decay,\n",
        "                        step_clip_ratio=step_clip_ratio, momentum_coeff=momentum_coeff, rank=rank, K=K)\n",
        "        super(SUMO, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            # Load params\n",
        "            step_size = group['step_size']\n",
        "            scale_factor = group['scale_factor']\n",
        "            weight_decay = group['weight_decay']\n",
        "            rank = group['rank']\n",
        "            K = group['K']\n",
        "            step_clip_ratio = group['step_clip_ratio']\n",
        "            momentum_coeff = group['momentum_coeff']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None: continue\n",
        "\n",
        "                # FIX 1: Handle 1D params (Bias/LayerNorm) via standard SGD/Adam logic\n",
        "                if p.dim() < 2:\n",
        "                    # Simple SGD + Weight Decay fallback for vectors\n",
        "                    p.data.mul_(1 - step_size * weight_decay)\n",
        "                    p.data.add_(p.grad, alpha=-step_size)\n",
        "                    continue\n",
        "\n",
        "                g = p.grad\n",
        "                state = self.state[p]\n",
        "\n",
        "                # Init step tracker\n",
        "                if 'step' not in state: state['step'] = 0\n",
        "\n",
        "                # Transpose handling for Fat Matrices (m < n)\n",
        "                m, n = g.size(-2), g.size(-1)\n",
        "                rev = (m < n)\n",
        "                if rev:\n",
        "                    g = g.transpose(-2, -1)\n",
        "                    # Update m, n after transpose to reflect the working shape\n",
        "                    m, n = g.size(-2), g.size(-1)\n",
        "\n",
        "                # Determine effective rank\n",
        "                k_limit = min(m, n)\n",
        "\n",
        "                # --- BLOCK 1: Subspace Update ---\n",
        "                # FIX 2: Correct Variable Scoping for U\n",
        "                if state['step'] % K == 0:\n",
        "                    # Compute new subspace\n",
        "                    if rank >= k_limit:\n",
        "                        U, S, Vh = torch.linalg.svd(g.float(), full_matrices=False)\n",
        "                        # In full rank case, effective U is (m, n)\n",
        "                    else:\n",
        "                        U, S, Vh = torch.svd_lowrank(g.float(), q=rank)\n",
        "                        # U is (m, r)\n",
        "\n",
        "                    # Initialize buffers if first step\n",
        "                    if 'sub_moment_buffer' not in state:\n",
        "                        state['sub_moment_buffer'] = U\n",
        "                        state['moment_buffer'] = torch.zeros(U.shape[1], n, device=g.device)\n",
        "                        state['orthogonal_buf'] = torch.zeros(U.shape[1], n, device=g.device)\n",
        "                        # No rotation on very first step\n",
        "                        moment_in_subspace = state['moment_buffer']\n",
        "                    else:\n",
        "                        # Rotation Logic\n",
        "                        # R = Q_new.T @ Q_old\n",
        "                        R = U.transpose(-2, -1) @ state['sub_moment_buffer']\n",
        "\n",
        "                        # Rotate the existing moment into new subspace\n",
        "                        # FIX 3: Use the rotated moment for the current update\n",
        "                        moment_in_subspace = R @ state['moment_buffer']\n",
        "\n",
        "                        # Store new basis\n",
        "                        state['sub_moment_buffer'] = U\n",
        "                else:\n",
        "                    # Retrieve existing subspace\n",
        "                    U = state['sub_moment_buffer']\n",
        "                    moment_in_subspace = state['moment_buffer']\n",
        "\n",
        "                # --- BLOCK 1.5: Projected Gradient ---\n",
        "                # G_hat = Q.T @ G\n",
        "                G_hat = U.transpose(-2, -1) @ g\n",
        "\n",
        "                # --- BLOCK 2: Moment Update & Orthogonalization ---\n",
        "                # FIX 3 (Cont): We use 'moment_in_subspace' which is either\n",
        "                # correctly rotated (if t%K==0) or loaded from state (if t%K!=0)\n",
        "                M = momentum_coeff * moment_in_subspace + G_hat\n",
        "\n",
        "                # Store the updated M back to state immediately\n",
        "                state['moment_buffer'] = M\n",
        "\n",
        "                # Orthogonalize\n",
        "                O = orthogonalization_svd(M)\n",
        "\n",
        "                # --- BLOCK 3: Norm Growth Limiter ---\n",
        "                o_norm = torch.norm(O)\n",
        "                prev_o_norm = torch.norm(state['orthogonal_buf'])\n",
        "\n",
        "                # FIX 4: Prevent zeroing out on the first step\n",
        "                if prev_o_norm > 1e-8 and o_norm > step_clip_ratio * prev_o_norm:\n",
        "                    scale = (step_clip_ratio * prev_o_norm) / o_norm\n",
        "                    O = O * scale\n",
        "\n",
        "                state['orthogonal_buf'] = O\n",
        "\n",
        "                # --- BLOCK 4: Weight Update ---\n",
        "                # Project back: Q @ (G_hat - O)\n",
        "                # Correction term is: alpha * (G_perp + Q @ O)\n",
        "                # Equivalent to: alpha * (G - Q @ G_hat + Q @ O) -> alpha * (G - Q @ (G_hat - O))\n",
        "\n",
        "                # The orthogonal update term\n",
        "                low_rank_update = U @ (G_hat - O)\n",
        "\n",
        "                # Combine: G - (G - Q G_hat + Q O) = G - G_perp - Q O\n",
        "                # Wait, paper formula: W_t = W_{t-1} - eta * (alpha * (G - Q(G_hat - O)))\n",
        "                # Note: The code below implements this exactly.\n",
        "\n",
        "                update_direction = g - low_rank_update.view_as(g)\n",
        "\n",
        "                # FIX 5: Apply Weight Decay to Weights (AdamW style), not Gradients\n",
        "                p.data.mul_(1 - step_size * weight_decay)\n",
        "\n",
        "                # Apply Gradient Update\n",
        "                final_update = scale_factor * update_direction\n",
        "\n",
        "                # Handle transpose back if needed\n",
        "                if rev:\n",
        "                    final_update = final_update.transpose(-2, -1)\n",
        "\n",
        "                p.data.add_(final_update, alpha=-step_size)\n",
        "\n",
        "                state['step'] += 1\n"
      ],
      "metadata": {
        "id": "F6Ypi0HZPazp"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.compile\n",
        "def orthogonalization_svd(M):\n",
        "  U,sig,V = torch.linalg.svd(M.float(), full_matrices=False) # TODO: figuring out full_matrices=True case\n",
        "  return U @ V\n",
        "\n",
        "class SUMO(torch.optim.Optimizer):\n",
        "  def __init__(self, params, step_size=1e-4, scale_factor=2.0, weight_decay=0.01,\n",
        "                rank=4, K=200, step_clip_ratio=1.1, momentum_coeff=0.9):\n",
        "      defaults = dict(step_size=step_size, scale_factor=scale_factor, weight_decay=weight_decay,\n",
        "                      step_clip_ratio=step_clip_ratio, momentum_coeff=momentum_coeff, rank=rank, K=K)\n",
        "      super(SUMO, self).__init__(params, defaults)\n",
        "\n",
        "  def __setstate__(self, state):\n",
        "    super(SUMO, self).__setstate__(state)\n",
        "\n",
        "  # tracking epoch number manually in the training loop\n",
        "  def step(self):\n",
        "    for group in self.param_groups:\n",
        "      step_size = group['step_size']\n",
        "      scale_factor = group['scale_factor']\n",
        "      weight_decay = group['weight_decay']\n",
        "      rank = group['rank']\n",
        "      K = group['K']\n",
        "      step_clip_ratio = group['step_clip_ratio']\n",
        "      momentum_coeff = group['momentum_coeff']\n",
        "\n",
        "      # mul_, add_ and other inplace ops would only be used when manipulating internal gradient ops.\n",
        "      for p in group['params']:\n",
        "        g = p.grad # the gradient matrix for w_t-1\n",
        "        if g is None: continue\n",
        "\n",
        "        if p.dim() < 2: # logic for handling bias/layernorm like param\n",
        "           p.data.mul_(1 - step_size * weight_decay)\n",
        "           p.data.add_(p.grad, alpha=-step_size)\n",
        "\n",
        "        state = self.state[p] # current state of the optimizer\n",
        "\n",
        "        m, n = g.size(-2), g.size(-1)\n",
        "        # m >= n assumption without loss of generality. [if n > m we transpose]\n",
        "        # also min(m, n) = n\n",
        "        if (rev:=(m<n)) : g = g.transpose(-2, -1)\n",
        "        if 'epoch_num' not in state.keys(): state['epoch_num'] = 0\n",
        "\n",
        "        if state['epoch_num'] % K == 0:\n",
        "          if rank > (k:=min(m, n)): U, sig, V = torch.linalg.svd(g.float(), full_matrices=False) # U shape : (m, n)\n",
        "          else: U, sig, V = torch.svd_lowrank(g.float(), q=rank) # svd(n,m) => (n,r), (r,r), (r,m)\n",
        "          if 'sub_moment_buffer' not in state.keys(): # first time we are encountering this at t=0\n",
        "            if rank <= k:\n",
        "              state['sub_moment_buffer'] = torch.eye(rank) # (rank, rank)\n",
        "              state['moment_buffer'] = torch.zeros(rank, n) # (rank, n)\n",
        "            else:\n",
        "              state['sub_moment_buffer'] = torch.eye(k) # (n, n)\n",
        "              state['moment_buffer'] = torch.zeros(k, k) # (k, n) -> (n, n)\n",
        "          else:\n",
        "            R = U.transpose(-2,-1) @ state['sub_moment_buffer'] # Q_t @ Q_(t-1)\n",
        "            M = R @ state['moment_buffer'] # R @ M_(t-1)\n",
        "\n",
        "        G_hat = U.transpose(-2, -1) @ g # (r, n) if rank <= k else (k, n) -> (n, n)\n",
        "        M = momentum_coeff * state['moment_buffer'] + G_hat # (r, n) if rank <= k else (k, n)\n",
        "\n",
        "        if 'orthogonal_buf' not in state.keys():\n",
        "          state['orthogonal_buf'] = torch.zeros(rank, n) if rank <= k else torch.zeros(k, n) # (rank, n) if rank <= k else (k, n)\n",
        "        O = orthogonalization_svd(M) # (r, n) if r <= k else (k, n)\n",
        "\n",
        "        if ((o_norm:=torch.norm(O)) > step_clip_ratio * (moment_norm:=torch.norm(state['orthogonal_buf']))):\n",
        "          O = (O / o_norm) * (step_clip_ratio * moment_norm) # (r, n) if r <= k else (k, n)\n",
        "\n",
        "        # weight updates\n",
        "        try:\n",
        "          update = step_size*weight_decay*g + scale_factor*step_size*(g - (U@(G_hat - O)).view_as(g))\n",
        "        except Exception as e:\n",
        "          print(f\"G_hat shape: {G_hat.shape}, O shape: {O.shape}, g shape: {g.shape}, U shape: {U.shape}, M shape: {M.shape}\")\n",
        "\n",
        "        p.data.add_(update.transpose(-2, -1) if rev else update, alpha=-1.0)\n",
        "        # update the buffers\n",
        "        state['sub_moment_buffer'] = U\n",
        "        state['moment_buffer'] = M\n",
        "        state['orthogonal_buf'] = O"
      ],
      "metadata": {
        "id": "zBVmO_xIiT3u"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(2, 4, bias=False)\n",
        "    self.fc2 = nn.Linear(4, 8, bias=False)\n",
        "    self.fc3 = nn.Linear(8, 16, bias=False)\n",
        "    self.fc4 = nn.Linear(16, 64, bias=False)\n",
        "    self.out = nn.Linear(64, 1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = torch.relu(self.fc3(self.fc2(x)))\n",
        "    x = self.fc4(x)\n",
        "    return torch.sigmoid(self.out(x))\n",
        "\n",
        "def generate_big_xor(n=2000):\n",
        "    X = torch.randn(n, 2)  # random points in 2D\n",
        "    y = ((X[:, 0] > 0) ^ (X[:, 1] > 0)).float().unsqueeze(1)\n",
        "    return X, y\n",
        "\n",
        "# train/test split\n",
        "X_train, y_train = generate_big_xor(2000)\n",
        "X_test,  y_test  = generate_big_xor(2000)\n",
        "\n",
        "train_data = [(X_train[i], y_train[i]) for i in range(len(X_train))]\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "model = TinyNet()\n",
        "# opt = SUMO(model.parameters(), 1e-3, 1.0, 1.0, 2, 5, 1.1, 1.0)\n",
        "opt = SUMO(model.parameters())\n",
        "opt.state['epoch_num'] = 0"
      ],
      "metadata": {
        "id": "34G2cXLswjPQ"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(X, y):\n",
        "  with torch.no_grad():\n",
        "    preds = (model(X) > 0.5).float()\n",
        "    return (preds == y).float().mean().item()\n",
        "\n",
        "for epoch in range(100):\n",
        "  for xb, yb in train_loader:\n",
        "    opt.zero_grad()\n",
        "    loss = criterion(model(xb), yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.state['epoch_num'] += 1\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    train_acc = accuracy(X_train, y_train)\n",
        "    test_acc  = accuracy(X_test,  y_test)\n",
        "    print(f\"epoch={epoch}, loss={loss.item():.4f}, train_acc={train_acc:.3f}, test_acc={test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7ouTHF-wjLj",
        "outputId": "48ed2ad0-3959-49fd-f43d-56a48fd2dfa1"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0, loss=0.6941, train_acc=0.476, test_acc=0.495\n",
            "epoch=5, loss=0.6958, train_acc=0.476, test_acc=0.495\n",
            "epoch=10, loss=0.6946, train_acc=0.476, test_acc=0.495\n",
            "epoch=15, loss=0.6957, train_acc=0.476, test_acc=0.495\n",
            "epoch=20, loss=0.6966, train_acc=0.476, test_acc=0.495\n",
            "epoch=25, loss=0.6949, train_acc=0.476, test_acc=0.495\n",
            "epoch=30, loss=0.6933, train_acc=0.476, test_acc=0.495\n",
            "epoch=35, loss=0.6941, train_acc=0.476, test_acc=0.495\n",
            "epoch=40, loss=0.6944, train_acc=0.476, test_acc=0.495\n",
            "epoch=45, loss=0.6951, train_acc=0.476, test_acc=0.495\n",
            "epoch=50, loss=0.6963, train_acc=0.476, test_acc=0.495\n",
            "epoch=55, loss=0.6965, train_acc=0.476, test_acc=0.495\n",
            "epoch=60, loss=0.6940, train_acc=0.476, test_acc=0.495\n",
            "epoch=65, loss=0.6917, train_acc=0.476, test_acc=0.495\n",
            "epoch=70, loss=0.6944, train_acc=0.476, test_acc=0.495\n",
            "epoch=75, loss=0.6959, train_acc=0.476, test_acc=0.495\n",
            "epoch=80, loss=0.6965, train_acc=0.476, test_acc=0.495\n",
            "epoch=85, loss=0.6959, train_acc=0.476, test_acc=0.495\n",
            "epoch=90, loss=0.6966, train_acc=0.476, test_acc=0.495\n",
            "epoch=95, loss=0.6936, train_acc=0.476, test_acc=0.495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_adam = nn.BCELoss()\n",
        "model2 = TinyNet()\n",
        "adam = torch.optim.Adam(model2.parameters())"
      ],
      "metadata": {
        "id": "itHkDdhcwjJX"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(X, y):\n",
        "  with torch.no_grad():\n",
        "    preds = (model2(X) > 0.5).float()\n",
        "    return (preds == y).float().mean().item()\n",
        "\n",
        "for epoch in range(50):\n",
        "  for xb, yb in train_loader:\n",
        "    adam.zero_grad()\n",
        "    loss = criterion_adam(model2(xb), yb)\n",
        "    loss.backward()\n",
        "    adam.step()\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "    train_acc = accuracy(X_train, y_train)\n",
        "    test_acc  = accuracy(X_test,  y_test)\n",
        "    print(f\"epoch={epoch}, loss={loss.item():.4f}, train_acc={train_acc:.3f}, test_acc={test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQVExLPWwjG6",
        "outputId": "b908abb6-edc3-4e06-ab56-b1bf95cbeb29"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0, loss=0.6345, train_acc=0.627, test_acc=0.618\n",
            "epoch=5, loss=0.0592, train_acc=0.979, test_acc=0.986\n",
            "epoch=10, loss=0.0314, train_acc=0.994, test_acc=0.996\n",
            "epoch=15, loss=0.0087, train_acc=0.997, test_acc=0.995\n",
            "epoch=20, loss=0.0052, train_acc=0.992, test_acc=0.996\n",
            "epoch=25, loss=0.0003, train_acc=0.994, test_acc=0.997\n",
            "epoch=30, loss=0.0711, train_acc=0.996, test_acc=0.999\n",
            "epoch=35, loss=0.0000, train_acc=0.996, test_acc=0.995\n",
            "epoch=40, loss=0.0308, train_acc=0.994, test_acc=0.994\n",
            "epoch=45, loss=0.0000, train_acc=0.998, test_acc=0.998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7gFJDccSMk9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xEQMyoX5Mk5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pshP_KROm-6Q",
        "outputId": "6aa8517f-3ca5-4a6e-fef4-2bbd8f383a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:39: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:39: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-2716417740.py:39: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  where S' is diagonal with S_{ii}' \\sim Uniform(0.5, 1.5), which turns out not to hurt model\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "airbench94_muon.py\n",
        "Runs in 2.59 seconds on a 400W NVIDIA A100\n",
        "Attains 94.004 mean accuracy (n=200 trials)\n",
        "Descends from https://github.com/tysam-code/hlb-CIFAR10/blob/main/main.py\n",
        "\"\"\"\n",
        "\n",
        "#############################################\n",
        "#                  Setup                    #\n",
        "#############################################\n",
        "\n",
        "import os\n",
        "import sys\n",
        "with open(sys.argv[0]) as f:\n",
        "    code = f.read()\n",
        "import uuid\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "#############################################\n",
        "#               Muon optimizer              #\n",
        "#############################################\n",
        "\n",
        "@torch.compile\n",
        "def zeropower_via_newtonschulz5(G, steps=3, eps=1e-7):\n",
        "    \"\"\"\n",
        "    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a\n",
        "    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose\n",
        "    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at\n",
        "    zero even beyond the point where the iteration no longer converges all the way to one everywhere\n",
        "    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T\n",
        "    where S' is diagonal with S_{ii}' \\sim Uniform(0.5, 1.5), which turns out not to hurt model\n",
        "    performance at all relative to UV^T, where USV^T = G is the SVD.\n",
        "    \"\"\"\n",
        "    assert len(G.shape) == 2\n",
        "    a, b, c = (3.4445, -4.7750,  2.0315)\n",
        "    # X = G.bfloat16()\n",
        "    X = G.half()\n",
        "    X /= (X.norm() + eps) # ensure top singular value <= 1\n",
        "    if G.size(0) > G.size(1):\n",
        "        X = X.T\n",
        "    for _ in range(steps):\n",
        "        A = X @ X.T\n",
        "        B = b * A + c * A @ A\n",
        "        X = a * X + B @ X\n",
        "    if G.size(0) > G.size(1):\n",
        "        X = X.T\n",
        "    return X\n",
        "\n",
        "class Muon(torch.optim.Optimizer):\n",
        "    def __init__(self, params, lr=1e-3, momentum=0, nesterov=False):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
        "        if momentum < 0.0:\n",
        "            raise ValueError(f\"Invalid momentum value: {momentum}\")\n",
        "        if nesterov and momentum <= 0:\n",
        "            raise ValueError(\"Nesterov momentum requires a momentum\")\n",
        "        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    def step(self):\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            momentum = group['momentum']\n",
        "            for p in group['params']:\n",
        "                g = p.grad\n",
        "                if g is None:\n",
        "                    continue\n",
        "                state = self.state[p]\n",
        "\n",
        "                if 'momentum_buffer' not in state.keys():\n",
        "                    state['momentum_buffer'] = torch.zeros_like(g)\n",
        "                buf = state['momentum_buffer']\n",
        "                buf.mul_(momentum).add_(g)\n",
        "                g = g.add(buf, alpha=momentum) if group['nesterov'] else buf\n",
        "\n",
        "                p.data.mul_(len(p.data)**0.5 / p.data.norm()) # normalize the weight\n",
        "                update = zeropower_via_newtonschulz5(g.reshape(len(g), -1)).view(g.shape) # whiten the update\n",
        "                p.data.add_(update, alpha=-lr) # take a step\n",
        "\n",
        "#############################################\n",
        "#                DataLoader                 #\n",
        "#############################################\n",
        "\n",
        "CIFAR_MEAN = torch.tensor((0.4914, 0.4822, 0.4465))\n",
        "CIFAR_STD = torch.tensor((0.2470, 0.2435, 0.2616))\n",
        "\n",
        "def batch_flip_lr(inputs):\n",
        "    flip_mask = (torch.rand(len(inputs), device=inputs.device) < 0.5).view(-1, 1, 1, 1)\n",
        "    return torch.where(flip_mask, inputs.flip(-1), inputs)\n",
        "\n",
        "def batch_crop(images, crop_size):\n",
        "    r = (images.size(-1) - crop_size)//2\n",
        "    shifts = torch.randint(-r, r+1, size=(len(images), 2), device=images.device)\n",
        "    images_out = torch.empty((len(images), 3, crop_size, crop_size), device=images.device, dtype=images.dtype)\n",
        "    # The two cropping methods in this if-else produce equivalent results, but the second is faster for r > 2.\n",
        "    if r <= 2:\n",
        "        for sy in range(-r, r+1):\n",
        "            for sx in range(-r, r+1):\n",
        "                mask = (shifts[:, 0] == sy) & (shifts[:, 1] == sx)\n",
        "                images_out[mask] = images[mask, :, r+sy:r+sy+crop_size, r+sx:r+sx+crop_size]\n",
        "    else:\n",
        "        images_tmp = torch.empty((len(images), 3, crop_size, crop_size+2*r), device=images.device, dtype=images.dtype)\n",
        "        for s in range(-r, r+1):\n",
        "            mask = (shifts[:, 0] == s)\n",
        "            images_tmp[mask] = images[mask, :, r+s:r+s+crop_size, :]\n",
        "        for s in range(-r, r+1):\n",
        "            mask = (shifts[:, 1] == s)\n",
        "            images_out[mask] = images_tmp[mask, :, :, r+s:r+s+crop_size]\n",
        "    return images_out\n",
        "\n",
        "class CifarLoader:\n",
        "\n",
        "    def __init__(self, path, train=True, batch_size=500, aug=None):\n",
        "        data_path = os.path.join(path, 'train.pt' if train else 'test.pt')\n",
        "        if not os.path.exists(data_path):\n",
        "            dset = torchvision.datasets.CIFAR10(path, download=True, train=train)\n",
        "            images = torch.tensor(dset.data)\n",
        "            labels = torch.tensor(dset.targets)\n",
        "            torch.save({'images': images, 'labels': labels, 'classes': dset.classes}, data_path)\n",
        "\n",
        "        data = torch.load(data_path, map_location=torch.device('cuda'))\n",
        "        self.images, self.labels, self.classes = data['images'], data['labels'], data['classes']\n",
        "        # It's faster to load+process uint8 data than to load preprocessed fp16 data\n",
        "        self.images = (self.images.half() / 255).permute(0, 3, 1, 2).to(memory_format=torch.channels_last)\n",
        "\n",
        "        self.normalize = T.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
        "        self.proc_images = {} # Saved results of image processing to be done on the first epoch\n",
        "        self.epoch = 0\n",
        "\n",
        "        self.aug = aug or {}\n",
        "        for k in self.aug.keys():\n",
        "            assert k in ['flip', 'translate'], 'Unrecognized key: %s' % k\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.drop_last = train\n",
        "        self.shuffle = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)//self.batch_size if self.drop_last else ceil(len(self.images)/self.batch_size)\n",
        "\n",
        "    def __iter__(self):\n",
        "\n",
        "        if self.epoch == 0:\n",
        "            images = self.proc_images['norm'] = self.normalize(self.images)\n",
        "            # Pre-flip images in order to do every-other epoch flipping scheme\n",
        "            if self.aug.get('flip', False):\n",
        "                images = self.proc_images['flip'] = batch_flip_lr(images)\n",
        "            # Pre-pad images to save time when doing random translation\n",
        "            pad = self.aug.get('translate', 0)\n",
        "            if pad > 0:\n",
        "                self.proc_images['pad'] = F.pad(images, (pad,)*4, 'reflect')\n",
        "\n",
        "        if self.aug.get('translate', 0) > 0:\n",
        "            images = batch_crop(self.proc_images['pad'], self.images.shape[-2])\n",
        "        elif self.aug.get('flip', False):\n",
        "            images = self.proc_images['flip']\n",
        "        else:\n",
        "            images = self.proc_images['norm']\n",
        "        # Flip all images together every other epoch. This increases diversity relative to random flipping\n",
        "        if self.aug.get('flip', False):\n",
        "            if self.epoch % 2 == 1:\n",
        "                images = images.flip(-1)\n",
        "\n",
        "        self.epoch += 1\n",
        "\n",
        "        indices = (torch.randperm if self.shuffle else torch.arange)(len(images), device=images.device)\n",
        "        for i in range(len(self)):\n",
        "            idxs = indices[i*self.batch_size:(i+1)*self.batch_size]\n",
        "            yield (images[idxs], self.labels[idxs])\n",
        "\n",
        "#############################################\n",
        "#            Network Definition             #\n",
        "#############################################\n",
        "\n",
        "# note the use of low BatchNorm stats momentum\n",
        "class BatchNorm(nn.BatchNorm2d):\n",
        "    def __init__(self, num_features, momentum=0.6, eps=1e-12):\n",
        "        super().__init__(num_features, eps=eps, momentum=1-momentum)\n",
        "        self.weight.requires_grad = False\n",
        "        # Note that PyTorch already initializes the weights to one and bias to zero\n",
        "\n",
        "class Conv(nn.Conv2d):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__(in_channels, out_channels, kernel_size=3, padding='same', bias=False)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()\n",
        "        w = self.weight.data\n",
        "        torch.nn.init.dirac_(w[:w.size(1)])\n",
        "\n",
        "class ConvGroup(nn.Module):\n",
        "    def __init__(self, channels_in, channels_out):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv(channels_in,  channels_out)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.norm1 = BatchNorm(channels_out)\n",
        "        self.conv2 = Conv(channels_out, channels_out)\n",
        "        self.norm2 = BatchNorm(channels_out)\n",
        "        self.activ = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.activ(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.activ(x)\n",
        "        return x\n",
        "\n",
        "class CifarNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        widths = dict(block1=64, block2=256, block3=256)\n",
        "        whiten_kernel_size = 2\n",
        "        whiten_width = 2 * 3 * whiten_kernel_size**2\n",
        "        self.whiten = nn.Conv2d(3, whiten_width, whiten_kernel_size, padding=0, bias=True)\n",
        "        self.whiten.weight.requires_grad = False\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.GELU(),\n",
        "            ConvGroup(whiten_width,     widths['block1']),\n",
        "            ConvGroup(widths['block1'], widths['block2']),\n",
        "            ConvGroup(widths['block2'], widths['block3']),\n",
        "            nn.MaxPool2d(3),\n",
        "        )\n",
        "        self.head = nn.Linear(widths['block3'], 10, bias=False)\n",
        "        for mod in self.modules():\n",
        "            if isinstance(mod, BatchNorm):\n",
        "                mod.float()\n",
        "            else:\n",
        "                mod.half()\n",
        "\n",
        "    def reset(self):\n",
        "        for m in model.modules():\n",
        "            if type(m) in (nn.Conv2d, Conv, BatchNorm, nn.Linear):\n",
        "                m.reset_parameters()\n",
        "        w = self.head.weight.data\n",
        "        w *= 1 / w.std()\n",
        "\n",
        "    def init_whiten(self, train_images, eps=5e-4):\n",
        "        c, (h, w) = train_images.shape[1], self.whiten.weight.shape[2:]\n",
        "        patches = train_images.unfold(2,h,1).unfold(3,w,1).transpose(1,3).reshape(-1,c,h,w).float()\n",
        "        patches_flat = patches.view(len(patches), -1)\n",
        "        est_patch_covariance = (patches_flat.T @ patches_flat) / len(patches_flat)\n",
        "        eigenvalues, eigenvectors = torch.linalg.eigh(est_patch_covariance, UPLO='U')\n",
        "        eigenvectors_scaled = eigenvectors.T.reshape(-1,c,h,w) / torch.sqrt(eigenvalues.view(-1,1,1,1) + eps)\n",
        "        self.whiten.weight.data[:] = torch.cat((eigenvectors_scaled, -eigenvectors_scaled))\n",
        "\n",
        "    def forward(self, x, whiten_bias_grad=True):\n",
        "        b = self.whiten.bias\n",
        "        x = F.conv2d(x, self.whiten.weight, b if whiten_bias_grad else b.detach())\n",
        "        x = self.layers(x)\n",
        "        x = x.view(len(x), -1)\n",
        "        return self.head(x) / x.size(-1)\n",
        "\n",
        "############################################\n",
        "#                 Logging                  #\n",
        "############################################\n",
        "\n",
        "def print_columns(columns_list, is_head=False, is_final_entry=False):\n",
        "    print_string = ''\n",
        "    for col in columns_list:\n",
        "        print_string += '|  %s  ' % col\n",
        "    print_string += '|'\n",
        "    if is_head:\n",
        "        print('-'*len(print_string))\n",
        "    print(print_string)\n",
        "    if is_head or is_final_entry:\n",
        "        print('-'*len(print_string))\n",
        "\n",
        "logging_columns_list = ['run   ', 'epoch', 'train_acc', 'val_acc', 'tta_val_acc', 'time_seconds']\n",
        "def print_training_details(variables, is_final_entry):\n",
        "    formatted = []\n",
        "    for col in logging_columns_list:\n",
        "        var = variables.get(col.strip(), None)\n",
        "        if type(var) in (int, str):\n",
        "            res = str(var)\n",
        "        elif type(var) is float:\n",
        "            res = '{:0.4f}'.format(var)\n",
        "        else:\n",
        "            assert var is None\n",
        "            res = ''\n",
        "        formatted.append(res.rjust(len(col)))\n",
        "    print_columns(formatted, is_final_entry=is_final_entry)\n",
        "\n",
        "############################################\n",
        "#               Evaluation                 #\n",
        "############################################\n",
        "\n",
        "def infer(model, loader, tta_level=0):\n",
        "\n",
        "    # Test-time augmentation strategy (for tta_level=2):\n",
        "    # 1. Flip/mirror the image left-to-right (50% of the time).\n",
        "    # 2. Translate the image by one pixel either up-and-left or down-and-right (50% of the time,\n",
        "    #    i.e. both happen 25% of the time).\n",
        "    #\n",
        "    # This creates 6 views per image (left/right times the two translations and no-translation),\n",
        "    # which we evaluate and then weight according to the given probabilities.\n",
        "\n",
        "    def infer_basic(inputs, net):\n",
        "        return net(inputs).clone()\n",
        "\n",
        "    def infer_mirror(inputs, net):\n",
        "        return 0.5 * net(inputs) + 0.5 * net(inputs.flip(-1))\n",
        "\n",
        "    def infer_mirror_translate(inputs, net):\n",
        "        logits = infer_mirror(inputs, net)\n",
        "        pad = 1\n",
        "        padded_inputs = F.pad(inputs, (pad,)*4, 'reflect')\n",
        "        inputs_translate_list = [\n",
        "            padded_inputs[:, :, 0:32, 0:32],\n",
        "            padded_inputs[:, :, 2:34, 2:34],\n",
        "        ]\n",
        "        logits_translate_list = [infer_mirror(inputs_translate, net)\n",
        "                                 for inputs_translate in inputs_translate_list]\n",
        "        logits_translate = torch.stack(logits_translate_list).mean(0)\n",
        "        return 0.5 * logits + 0.5 * logits_translate\n",
        "\n",
        "    model.eval()\n",
        "    test_images = loader.normalize(loader.images)\n",
        "    infer_fn = [infer_basic, infer_mirror, infer_mirror_translate][tta_level]\n",
        "    with torch.no_grad():\n",
        "        return torch.cat([infer_fn(inputs, model) for inputs in test_images.split(2000)])\n",
        "\n",
        "def evaluate(model, loader, tta_level=0):\n",
        "    logits = infer(model, loader, tta_level)\n",
        "    return (logits.argmax(1) == loader.labels).float().mean().item()\n",
        "\n",
        "############################################\n",
        "#                Training                  #\n",
        "############################################\n",
        "\n",
        "def main(run, model):\n",
        "\n",
        "    batch_size = 2000\n",
        "    bias_lr = 0.053\n",
        "    head_lr = 0.67\n",
        "    wd = 2e-6 * batch_size\n",
        "\n",
        "    test_loader = CifarLoader('cifar10', train=False, batch_size=512)\n",
        "    train_loader = CifarLoader('cifar10', train=True, batch_size=batch_size, aug=dict(flip=True, translate=2))\n",
        "    if run == 'warmup':\n",
        "        # The only purpose of the first run is to warmup the compiled model, so we can use dummy data\n",
        "        train_loader.labels = torch.randint(0, 10, size=(len(train_loader.labels),), device=train_loader.labels.device)\n",
        "    total_train_steps = ceil(8 * len(train_loader))\n",
        "    whiten_bias_train_steps = ceil(3 * len(train_loader))\n",
        "\n",
        "    # Create optimizers and learning rate schedulers\n",
        "    filter_params = [p for p in model.parameters() if len(p.shape) == 4 and p.requires_grad]\n",
        "    norm_biases = [p for n, p in model.named_parameters() if 'norm' in n and p.requires_grad]\n",
        "    param_configs = [dict(params=[model.whiten.bias], lr=bias_lr, weight_decay=wd/bias_lr),\n",
        "                     dict(params=norm_biases, lr=bias_lr, weight_decay=wd/bias_lr),\n",
        "                     dict(params=[model.head.weight], lr=head_lr, weight_decay=wd/head_lr)]\n",
        "    optimizer1 = torch.optim.SGD(param_configs, momentum=0.85, nesterov=True, fused=True)\n",
        "    optimizer2 = Muon(filter_params, lr=0.24, momentum=0.6, nesterov=True)\n",
        "    optimizers = [optimizer1, optimizer2]\n",
        "    for opt in optimizers:\n",
        "        for group in opt.param_groups:\n",
        "            group[\"initial_lr\"] = group[\"lr\"]\n",
        "\n",
        "    # For accurately timing GPU code\n",
        "    starter = torch.cuda.Event(enable_timing=True)\n",
        "    ender = torch.cuda.Event(enable_timing=True)\n",
        "    time_seconds = 0.0\n",
        "    def start_timer():\n",
        "        starter.record()\n",
        "    def stop_timer():\n",
        "        ender.record()\n",
        "        torch.cuda.synchronize()\n",
        "        nonlocal time_seconds\n",
        "        time_seconds += 1e-3 * starter.elapsed_time(ender)\n",
        "\n",
        "    model.reset()\n",
        "    step = 0\n",
        "\n",
        "    # Initialize the whitening layer using training images\n",
        "    start_timer()\n",
        "    train_images = train_loader.normalize(train_loader.images[:5000])\n",
        "    model.init_whiten(train_images)\n",
        "    stop_timer()\n",
        "\n",
        "    for epoch in range(ceil(total_train_steps / len(train_loader))):\n",
        "\n",
        "        ####################\n",
        "        #     Training     #\n",
        "        ####################\n",
        "\n",
        "        start_timer()\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            outputs = model(inputs, whiten_bias_grad=(step < whiten_bias_train_steps))\n",
        "            F.cross_entropy(outputs, labels, label_smoothing=0.2, reduction='sum').backward()\n",
        "            for group in optimizer1.param_groups[:1]:\n",
        "                group[\"lr\"] = group[\"initial_lr\"] * (1 - step / whiten_bias_train_steps)\n",
        "            for group in optimizer1.param_groups[1:]+optimizer2.param_groups:\n",
        "                group[\"lr\"] = group[\"initial_lr\"] * (1 - step / total_train_steps)\n",
        "            for opt in optimizers:\n",
        "                opt.step()\n",
        "            model.zero_grad(set_to_none=True)\n",
        "            step += 1\n",
        "            if step >= total_train_steps:\n",
        "                break\n",
        "        stop_timer()\n",
        "\n",
        "        ####################\n",
        "        #    Evaluation    #\n",
        "        ####################\n",
        "\n",
        "        # Save the accuracy and loss from the last training batch of the epoch\n",
        "        train_acc = (outputs.detach().argmax(1) == labels).float().mean().item()\n",
        "        val_acc = evaluate(model, test_loader, tta_level=0)\n",
        "        print_training_details(locals(), is_final_entry=False)\n",
        "        run = None # Only print the run number once\n",
        "\n",
        "    ####################\n",
        "    #  TTA Evaluation  #\n",
        "    ####################\n",
        "\n",
        "    start_timer()\n",
        "    tta_val_acc = evaluate(model, test_loader, tta_level=0)\n",
        "    stop_timer()\n",
        "    epoch = 'eval'\n",
        "    print_training_details(locals(), is_final_entry=True)\n",
        "\n",
        "    return tta_val_acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UITkSkyocCs",
        "outputId": "65767c90-0925-4b48-acf1-54bd7f6b14b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # We re-use the compiled model between runs to save the non-data-dependent compilation time\n",
        "    model = CifarNet().cuda().to(memory_format=torch.channels_last)\n",
        "    model.compile(mode='max-autotune')\n",
        "\n",
        "    print_columns(logging_columns_list, is_head=True)\n",
        "    main('warmup', model)\n",
        "    accs = torch.tensor([main(run, model) for run in range(200)])\n",
        "    print('Mean: %.4f    Std: %.4f' % (accs.mean(), accs.std()))\n",
        "\n",
        "    log_dir = os.path.join('logs', str(uuid.uuid4()))\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    log_path = os.path.join(log_dir, 'log.pt')\n",
        "    torch.save(dict(code=code, accs=accs), log_path)\n",
        "    print(os.path.abspath(log_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aKPJkK-mnF4Z",
        "outputId": "e8ddc7dc-dc55-482d-df1a-b6888fdd8f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------\n",
            "|  run     |  epoch  |  train_acc  |  val_acc  |  tta_val_acc  |  time_seconds  |\n",
            "---------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170M/170M [00:04<00:00, 40.4MB/s]\n",
            "W1119 05:57:30.700000 686 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|  warmup  |      0  |     0.0980  |   0.1028  |               |      105.6305  |\n",
            "|          |      1  |     0.1020  |   0.1011  |               |      108.1593  |\n",
            "|          |      2  |     0.1015  |   0.0478  |               |      110.6868  |\n",
            "|          |      3  |     0.1065  |   0.0955  |               |      156.2594  |\n",
            "|          |      4  |     0.1085  |   0.1273  |               |      158.7978  |\n",
            "|          |      5  |     0.1020  |   0.1214  |               |      161.3617  |\n",
            "|          |      6  |     0.1040  |   0.1127  |               |      163.9526  |\n",
            "|          |      7  |     0.1030  |   0.0945  |               |      166.5874  |\n",
            "|          |   eval  |     0.1030  |   0.0945  |       0.0945  |      166.7657  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       0  |      0  |     0.7370  |   0.6457  |               |        2.9034  |\n",
            "|          |      1  |     0.8155  |   0.7358  |               |        5.7790  |\n",
            "|          |      2  |     0.8710  |   0.8250  |               |        8.6163  |\n",
            "|          |      3  |     0.8925  |   0.8515  |               |       11.1781  |\n",
            "|          |      4  |     0.9130  |   0.8944  |               |       13.7234  |\n",
            "|          |      5  |     0.9330  |   0.9048  |               |       16.2746  |\n",
            "|          |      6  |     0.9545  |   0.9256  |               |       18.8021  |\n",
            "|          |      7  |     0.9755  |   0.9329  |               |       21.3197  |\n",
            "|          |   eval  |     0.9755  |   0.9329  |       0.9329  |       21.4800  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       1  |      0  |     0.6895  |   0.6683  |               |        2.7109  |\n",
            "|          |      1  |     0.8015  |   0.7025  |               |        5.3434  |\n",
            "|          |      2  |     0.8460  |   0.7963  |               |        7.9529  |\n",
            "|          |      3  |     0.8765  |   0.8660  |               |       10.3994  |\n",
            "|          |      4  |     0.8970  |   0.8897  |               |       12.8386  |\n",
            "|          |      5  |     0.9205  |   0.8888  |               |       15.2738  |\n",
            "|          |      6  |     0.9480  |   0.9263  |               |       17.7014  |\n",
            "|          |      7  |     0.9785  |   0.9324  |               |       20.1321  |\n",
            "|          |   eval  |     0.9785  |   0.9324  |       0.9324  |       20.2888  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       2  |      0  |     0.7210  |   0.6358  |               |        2.5930  |\n",
            "|          |      1  |     0.7870  |   0.5410  |               |        5.2177  |\n",
            "|          |      2  |     0.8480  |   0.7842  |               |        7.8464  |\n",
            "|          |      3  |     0.8895  |   0.8468  |               |       10.3135  |\n",
            "|          |      4  |     0.8965  |   0.8723  |               |       12.7843  |\n",
            "|          |      5  |     0.9390  |   0.8912  |               |       15.2739  |\n",
            "|          |      6  |     0.9470  |   0.9222  |               |       17.7665  |\n",
            "|          |      7  |     0.9720  |   0.9331  |               |       20.2808  |\n",
            "|          |   eval  |     0.9720  |   0.9331  |       0.9331  |       20.4406  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       3  |      0  |     0.7245  |   0.6581  |               |        2.6847  |\n",
            "|          |      1  |     0.8250  |   0.7788  |               |        5.3947  |\n",
            "|          |      2  |     0.8655  |   0.8100  |               |        8.1140  |\n",
            "|          |      3  |     0.8725  |   0.8276  |               |       10.6644  |\n",
            "|          |      4  |     0.9010  |   0.8738  |               |       13.2176  |\n",
            "|          |      5  |     0.9265  |   0.9065  |               |       15.7663  |\n",
            "|          |      6  |     0.9510  |   0.9200  |               |       18.3127  |\n",
            "|          |      7  |     0.9790  |   0.9323  |               |       20.8670  |\n",
            "|          |   eval  |     0.9790  |   0.9323  |       0.9323  |       21.0297  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       4  |      0  |     0.7295  |   0.5788  |               |        2.7145  |\n",
            "|          |      1  |     0.8120  |   0.6691  |               |        5.4394  |\n",
            "|          |      2  |     0.8525  |   0.8031  |               |        8.1676  |\n",
            "|          |      3  |     0.8670  |   0.8097  |               |       10.7203  |\n",
            "|          |      4  |     0.9020  |   0.8919  |               |       13.2538  |\n",
            "|          |      5  |     0.9365  |   0.8924  |               |       15.8007  |\n",
            "|          |      6  |     0.9485  |   0.9173  |               |       18.3295  |\n",
            "|          |      7  |     0.9745  |   0.9317  |               |       20.8827  |\n",
            "|          |   eval  |     0.9745  |   0.9317  |       0.9317  |       21.0469  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       5  |      0  |     0.7260  |   0.5934  |               |        2.6745  |\n",
            "|          |      1  |     0.8090  |   0.5920  |               |        5.3551  |\n",
            "|          |      2  |     0.8520  |   0.7666  |               |        8.0333  |\n",
            "|          |      3  |     0.8730  |   0.8531  |               |       10.5512  |\n",
            "|          |      4  |     0.9065  |   0.8716  |               |       13.0575  |\n",
            "|          |      5  |     0.9290  |   0.9001  |               |       15.5490  |\n",
            "|          |      6  |     0.9555  |   0.9193  |               |       18.0443  |\n",
            "|          |      7  |     0.9720  |   0.9301  |               |       20.5364  |\n",
            "|          |   eval  |     0.9720  |   0.9301  |       0.9301  |       20.6982  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       6  |      0  |     0.7300  |   0.6320  |               |        2.6532  |\n",
            "|          |      1  |     0.8370  |   0.7897  |               |        5.3239  |\n",
            "|          |      2  |     0.8310  |   0.7750  |               |        7.9938  |\n",
            "|          |      3  |     0.8755  |   0.8484  |               |       10.5187  |\n",
            "|          |      4  |     0.9015  |   0.8415  |               |       13.0269  |\n",
            "|          |      5  |     0.9240  |   0.8828  |               |       15.5556  |\n",
            "|          |      6  |     0.9650  |   0.9225  |               |       18.0923  |\n",
            "|          |      7  |     0.9755  |   0.9326  |               |       20.6277  |\n",
            "|          |   eval  |     0.9755  |   0.9326  |       0.9326  |       20.7916  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       7  |      0  |     0.7360  |   0.6838  |               |        2.6830  |\n",
            "|          |      1  |     0.8165  |   0.6859  |               |        5.3747  |\n",
            "|          |      2  |     0.8390  |   0.8012  |               |        8.0702  |\n",
            "|          |      3  |     0.8765  |   0.7938  |               |       10.6085  |\n",
            "|          |      4  |     0.9115  |   0.8816  |               |       13.1440  |\n",
            "|          |      5  |     0.9385  |   0.9018  |               |       15.7007  |\n",
            "|          |      6  |     0.9555  |   0.9255  |               |       18.2485  |\n",
            "|          |      7  |     0.9725  |   0.9308  |               |       20.7978  |\n",
            "|          |   eval  |     0.9725  |   0.9308  |       0.9308  |       20.9609  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       8  |      0  |     0.7035  |   0.6192  |               |        2.6789  |\n",
            "|          |      1  |     0.8145  |   0.7179  |               |        5.3711  |\n",
            "|          |      2  |     0.8540  |   0.7259  |               |        8.0757  |\n",
            "|          |      3  |     0.8805  |   0.8392  |               |       10.6167  |\n",
            "|          |      4  |     0.9090  |   0.8681  |               |       13.1484  |\n",
            "|          |      5  |     0.9275  |   0.8894  |               |       15.7039  |\n",
            "|          |      6  |     0.9580  |   0.9223  |               |       18.2350  |\n",
            "|          |      7  |     0.9825  |   0.9309  |               |       20.7542  |\n",
            "|          |   eval  |     0.9825  |   0.9309  |       0.9309  |       20.9147  |\n",
            "---------------------------------------------------------------------------------\n",
            "|       9  |      0  |     0.6985  |   0.6243  |               |        2.6747  |\n",
            "|          |      1  |     0.7825  |   0.6890  |               |        5.3626  |\n",
            "|          |      2  |     0.8565  |   0.7679  |               |        8.0470  |\n",
            "|          |      3  |     0.8880  |   0.8533  |               |       10.5917  |\n",
            "|          |      4  |     0.9205  |   0.8543  |               |       13.1197  |\n",
            "|          |      5  |     0.9410  |   0.9023  |               |       15.6309  |\n",
            "|          |      6  |     0.9580  |   0.9187  |               |       18.1465  |\n",
            "|          |      7  |     0.9760  |   0.9323  |               |       20.6678  |\n",
            "|          |   eval  |     0.9760  |   0.9323  |       0.9323  |       20.8284  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      10  |      0  |     0.7220  |   0.6486  |               |        2.6562  |\n",
            "|          |      1  |     0.8060  |   0.7155  |               |        5.3361  |\n",
            "|          |      2  |     0.8775  |   0.7906  |               |        8.0119  |\n",
            "|          |      3  |     0.8890  |   0.8539  |               |       10.5377  |\n",
            "|          |      4  |     0.9040  |   0.8751  |               |       13.0530  |\n",
            "|          |      5  |     0.9325  |   0.8996  |               |       15.5699  |\n",
            "|          |      6  |     0.9505  |   0.9248  |               |       18.0959  |\n",
            "|          |      7  |     0.9755  |   0.9337  |               |       20.6172  |\n",
            "|          |   eval  |     0.9755  |   0.9337  |       0.9337  |       20.7783  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      11  |      0  |     0.6975  |   0.6598  |               |        2.6509  |\n",
            "|          |      1  |     0.7980  |   0.7612  |               |        5.3270  |\n",
            "|          |      2  |     0.8625  |   0.7415  |               |        8.0073  |\n",
            "|          |      3  |     0.8695  |   0.8306  |               |       10.5287  |\n",
            "|          |      4  |     0.8965  |   0.8663  |               |       13.0358  |\n",
            "|          |      5  |     0.9385  |   0.9023  |               |       15.5504  |\n",
            "|          |      6  |     0.9570  |   0.9244  |               |       18.0637  |\n",
            "|          |      7  |     0.9800  |   0.9331  |               |       20.5756  |\n",
            "|          |   eval  |     0.9800  |   0.9331  |       0.9331  |       20.7378  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      12  |      0  |     0.7285  |   0.6891  |               |        2.6660  |\n",
            "|          |      1  |     0.8060  |   0.7304  |               |        5.3485  |\n",
            "|          |      2  |     0.8615  |   0.7834  |               |        8.0320  |\n",
            "|          |      3  |     0.8695  |   0.8585  |               |       10.5483  |\n",
            "|          |      4  |     0.9010  |   0.8539  |               |       13.0615  |\n",
            "|          |      5  |     0.9290  |   0.9105  |               |       15.5739  |\n",
            "|          |      6  |     0.9530  |   0.9228  |               |       18.0845  |\n",
            "|          |      7  |     0.9765  |   0.9319  |               |       20.5960  |\n",
            "|          |   eval  |     0.9765  |   0.9319  |       0.9319  |       20.7581  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      13  |      0  |     0.7270  |   0.6493  |               |        2.6515  |\n",
            "|          |      1  |     0.7945  |   0.6891  |               |        5.3290  |\n",
            "|          |      2  |     0.8375  |   0.8303  |               |        8.0074  |\n",
            "|          |      3  |     0.8740  |   0.8508  |               |       10.5358  |\n",
            "|          |      4  |     0.8915  |   0.8831  |               |       13.0453  |\n",
            "|          |      5  |     0.9320  |   0.8928  |               |       15.5604  |\n",
            "|          |      6  |     0.9520  |   0.9248  |               |       18.0779  |\n",
            "|          |      7  |     0.9770  |   0.9319  |               |       20.5875  |\n",
            "|          |   eval  |     0.9770  |   0.9319  |       0.9319  |       20.7499  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      14  |      0  |     0.7385  |   0.6791  |               |        2.6682  |\n",
            "|          |      1  |     0.8200  |   0.7519  |               |        5.3445  |\n",
            "|          |      2  |     0.8635  |   0.7923  |               |        8.0213  |\n",
            "|          |      3  |     0.8850  |   0.7858  |               |       10.5351  |\n",
            "|          |      4  |     0.8860  |   0.8802  |               |       13.0460  |\n",
            "|          |      5  |     0.9335  |   0.9050  |               |       15.5735  |\n",
            "|          |      6  |     0.9540  |   0.9251  |               |       18.0883  |\n",
            "|          |      7  |     0.9720  |   0.9317  |               |       20.5997  |\n",
            "|          |   eval  |     0.9720  |   0.9317  |       0.9317  |       20.7600  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      15  |      0  |     0.7455  |   0.6651  |               |        2.6476  |\n",
            "|          |      1  |     0.8075  |   0.5830  |               |        5.3264  |\n",
            "|          |      2  |     0.8415  |   0.7405  |               |        8.0132  |\n",
            "|          |      3  |     0.8665  |   0.8089  |               |       10.5272  |\n",
            "|          |      4  |     0.8930  |   0.8582  |               |       13.0549  |\n",
            "|          |      5  |     0.9245  |   0.9029  |               |       15.5705  |\n",
            "|          |      6  |     0.9550  |   0.9133  |               |       18.0864  |\n",
            "|          |      7  |     0.9800  |   0.9310  |               |       20.5984  |\n",
            "|          |   eval  |     0.9800  |   0.9310  |       0.9310  |       20.7616  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      16  |      0  |     0.7200  |   0.6471  |               |        2.6566  |\n",
            "|          |      1  |     0.7935  |   0.6605  |               |        5.3352  |\n",
            "|          |      2  |     0.8450  |   0.6877  |               |        8.0199  |\n",
            "|          |      3  |     0.8870  |   0.8567  |               |       10.5379  |\n",
            "|          |      4  |     0.9120  |   0.8747  |               |       13.0679  |\n",
            "|          |      5  |     0.9255  |   0.9050  |               |       15.5889  |\n",
            "|          |      6  |     0.9690  |   0.9202  |               |       18.1083  |\n",
            "|          |      7  |     0.9810  |   0.9305  |               |       20.6213  |\n",
            "|          |   eval  |     0.9810  |   0.9305  |       0.9305  |       20.7813  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      17  |      0  |     0.7320  |   0.6173  |               |        2.6679  |\n",
            "|          |      1  |     0.8125  |   0.7433  |               |        5.3558  |\n",
            "|          |      2  |     0.8615  |   0.7974  |               |        8.0429  |\n",
            "|          |      3  |     0.8780  |   0.8357  |               |       10.5725  |\n",
            "|          |      4  |     0.9050  |   0.8766  |               |       13.0982  |\n",
            "|          |      5  |     0.9335  |   0.9092  |               |       15.6109  |\n",
            "|          |      6  |     0.9605  |   0.9249  |               |       18.1242  |\n",
            "|          |      7  |     0.9810  |   0.9323  |               |       20.6364  |\n",
            "|          |   eval  |     0.9810  |   0.9323  |       0.9323  |       20.7972  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      18  |      0  |     0.7535  |   0.5639  |               |        2.6704  |\n",
            "|          |      1  |     0.8080  |   0.7462  |               |        5.3475  |\n",
            "|          |      2  |     0.8510  |   0.8204  |               |        8.0321  |\n",
            "|          |      3  |     0.8815  |   0.8367  |               |       10.5623  |\n",
            "|          |      4  |     0.9095  |   0.8813  |               |       13.0895  |\n",
            "|          |      5  |     0.9375  |   0.9018  |               |       15.6083  |\n",
            "|          |      6  |     0.9560  |   0.9192  |               |       18.1207  |\n",
            "|          |      7  |     0.9740  |   0.9312  |               |       20.6464  |\n",
            "|          |   eval  |     0.9740  |   0.9312  |       0.9312  |       20.8076  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      19  |      0  |     0.7340  |   0.7129  |               |        2.6643  |\n",
            "|          |      1  |     0.7985  |   0.6647  |               |        5.3410  |\n",
            "|          |      2  |     0.8625  |   0.8076  |               |        8.0210  |\n",
            "|          |      3  |     0.9005  |   0.8341  |               |       10.5489  |\n",
            "|          |      4  |     0.9065  |   0.8820  |               |       13.0840  |\n",
            "|          |      5  |     0.9235  |   0.8883  |               |       15.6076  |\n",
            "|          |      6  |     0.9545  |   0.9113  |               |       18.1252  |\n",
            "|          |      7  |     0.9765  |   0.9316  |               |       20.6437  |\n",
            "|          |   eval  |     0.9765  |   0.9316  |       0.9316  |       20.8039  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      20  |      0  |     0.7415  |   0.6504  |               |        2.6787  |\n",
            "|          |      1  |     0.8160  |   0.7649  |               |        5.3647  |\n",
            "|          |      2  |     0.8600  |   0.7833  |               |        8.0495  |\n",
            "|          |      3  |     0.8820  |   0.8426  |               |       10.5725  |\n",
            "|          |      4  |     0.9115  |   0.8640  |               |       13.1006  |\n",
            "|          |      5  |     0.9290  |   0.8984  |               |       15.6236  |\n",
            "|          |      6  |     0.9460  |   0.9194  |               |       18.1324  |\n",
            "|          |      7  |     0.9760  |   0.9318  |               |       20.6504  |\n",
            "|          |   eval  |     0.9760  |   0.9318  |       0.9318  |       20.8118  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      21  |      0  |     0.6915  |   0.6550  |               |        2.6669  |\n",
            "|          |      1  |     0.8190  |   0.7905  |               |        5.3461  |\n",
            "|          |      2  |     0.8515  |   0.8106  |               |        8.0286  |\n",
            "|          |      3  |     0.8855  |   0.8330  |               |       10.5581  |\n",
            "|          |      4  |     0.9150  |   0.8607  |               |       13.0720  |\n",
            "|          |      5  |     0.9405  |   0.8944  |               |       15.6016  |\n",
            "|          |      6  |     0.9480  |   0.9278  |               |       18.1161  |\n",
            "|          |      7  |     0.9765  |   0.9333  |               |       20.6335  |\n",
            "|          |   eval  |     0.9765  |   0.9333  |       0.9333  |       20.7949  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      22  |      0  |     0.7530  |   0.6435  |               |        2.6652  |\n",
            "|          |      1  |     0.8215  |   0.6973  |               |        5.3434  |\n",
            "|          |      2  |     0.8385  |   0.7886  |               |        8.0252  |\n",
            "|          |      3  |     0.8820  |   0.8146  |               |       10.5546  |\n",
            "|          |      4  |     0.9120  |   0.8797  |               |       13.0829  |\n",
            "|          |      5  |     0.9220  |   0.9080  |               |       15.5986  |\n",
            "|          |      6  |     0.9570  |   0.9249  |               |       18.1098  |\n",
            "|          |      7  |     0.9760  |   0.9349  |               |       20.6379  |\n",
            "|          |   eval  |     0.9760  |   0.9349  |       0.9349  |       20.7993  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      23  |      0  |     0.7420  |   0.5454  |               |        2.6653  |\n",
            "|          |      1  |     0.8110  |   0.7200  |               |        5.3452  |\n",
            "|          |      2  |     0.8615  |   0.8149  |               |        8.0308  |\n",
            "|          |      3  |     0.8785  |   0.8614  |               |       10.5641  |\n",
            "|          |      4  |     0.9115  |   0.8848  |               |       13.0983  |\n",
            "|          |      5  |     0.9220  |   0.9054  |               |       15.6323  |\n",
            "|          |      6  |     0.9455  |   0.9220  |               |       18.1662  |\n",
            "|          |      7  |     0.9755  |   0.9308  |               |       20.6994  |\n",
            "|          |   eval  |     0.9755  |   0.9308  |       0.9308  |       20.8603  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      24  |      0  |     0.7035  |   0.5793  |               |        2.6649  |\n",
            "|          |      1  |     0.7955  |   0.7174  |               |        5.3535  |\n",
            "|          |      2  |     0.8440  |   0.7674  |               |        8.0463  |\n",
            "|          |      3  |     0.8715  |   0.8146  |               |       10.5813  |\n",
            "|          |      4  |     0.9080  |   0.8916  |               |       13.1134  |\n",
            "|          |      5  |     0.9305  |   0.9057  |               |       15.6663  |\n",
            "|          |      6  |     0.9610  |   0.9218  |               |       18.1867  |\n",
            "|          |      7  |     0.9785  |   0.9326  |               |       20.7368  |\n",
            "|          |   eval  |     0.9785  |   0.9326  |       0.9326  |       20.8983  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      25  |      0  |     0.7225  |   0.6847  |               |        2.6868  |\n",
            "|          |      1  |     0.7990  |   0.7101  |               |        5.3720  |\n",
            "|          |      2  |     0.8460  |   0.7791  |               |        8.0592  |\n",
            "|          |      3  |     0.8725  |   0.8486  |               |       10.6007  |\n",
            "|          |      4  |     0.9040  |   0.8602  |               |       13.1370  |\n",
            "|          |      5  |     0.9320  |   0.9073  |               |       15.6582  |\n",
            "|          |      6  |     0.9550  |   0.9233  |               |       18.1906  |\n",
            "|          |      7  |     0.9780  |   0.9340  |               |       20.7246  |\n",
            "|          |   eval  |     0.9780  |   0.9340  |       0.9340  |       20.8883  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      26  |      0  |     0.7065  |   0.5696  |               |        2.6913  |\n",
            "|          |      1  |     0.8125  |   0.7512  |               |        5.3811  |\n",
            "|          |      2  |     0.8450  |   0.7944  |               |        8.0721  |\n",
            "|          |      3  |     0.8735  |   0.8263  |               |       10.6080  |\n",
            "|          |      4  |     0.9110  |   0.8924  |               |       13.1410  |\n",
            "|          |      5  |     0.9320  |   0.9004  |               |       15.6900  |\n",
            "|          |      6  |     0.9605  |   0.9216  |               |       18.2236  |\n",
            "|          |      7  |     0.9740  |   0.9323  |               |       20.7782  |\n",
            "|          |   eval  |     0.9740  |   0.9323  |       0.9323  |       20.9427  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      27  |      0  |     0.7135  |   0.5110  |               |        2.6805  |\n",
            "|          |      1  |     0.8120  |   0.7187  |               |        5.3699  |\n",
            "|          |      2  |     0.8330  |   0.7575  |               |        8.0730  |\n",
            "|          |      3  |     0.8820  |   0.8297  |               |       10.6243  |\n",
            "|          |      4  |     0.9135  |   0.8601  |               |       13.1767  |\n",
            "|          |      5  |     0.9195  |   0.8893  |               |       15.7292  |\n",
            "|          |      6  |     0.9445  |   0.9265  |               |       18.2587  |\n",
            "|          |      7  |     0.9740  |   0.9301  |               |       20.7958  |\n",
            "|          |   eval  |     0.9740  |   0.9301  |       0.9301  |       20.9595  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      28  |      0  |     0.7390  |   0.3509  |               |        2.6790  |\n",
            "|          |      1  |     0.8145  |   0.7813  |               |        5.3675  |\n",
            "|          |      2  |     0.8520  |   0.7753  |               |        8.0614  |\n",
            "|          |      3  |     0.8790  |   0.8313  |               |       10.5998  |\n",
            "|          |      4  |     0.9150  |   0.8753  |               |       13.1309  |\n",
            "|          |      5  |     0.9290  |   0.8898  |               |       15.6690  |\n",
            "|          |      6  |     0.9500  |   0.9251  |               |       18.2043  |\n",
            "|          |      7  |     0.9700  |   0.9320  |               |       20.7199  |\n",
            "|          |   eval  |     0.9700  |   0.9320  |       0.9320  |       20.8833  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      29  |      0  |     0.7255  |   0.6395  |               |        2.6825  |\n",
            "|          |      1  |     0.8220  |   0.6876  |               |        5.3792  |\n",
            "|          |      2  |     0.8715  |   0.7681  |               |        8.0640  |\n",
            "|          |      3  |     0.8840  |   0.8242  |               |       10.6088  |\n",
            "|          |      4  |     0.9115  |   0.8686  |               |       13.1435  |\n",
            "|          |      5  |     0.9270  |   0.9037  |               |       15.6750  |\n",
            "|          |      6  |     0.9550  |   0.9211  |               |       18.2078  |\n",
            "|          |      7  |     0.9755  |   0.9318  |               |       20.7631  |\n",
            "|          |   eval  |     0.9755  |   0.9318  |       0.9318  |       20.9254  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      30  |      0  |     0.7160  |   0.5960  |               |        2.6829  |\n",
            "|          |      1  |     0.7945  |   0.7689  |               |        5.3790  |\n",
            "|          |      2  |     0.8425  |   0.8055  |               |        8.0675  |\n",
            "|          |      3  |     0.8915  |   0.8298  |               |       10.6122  |\n",
            "|          |      4  |     0.9000  |   0.8901  |               |       13.1417  |\n",
            "|          |      5  |     0.9355  |   0.9041  |               |       15.6968  |\n",
            "|          |      6  |     0.9570  |   0.9252  |               |       18.2277  |\n",
            "|          |      7  |     0.9790  |   0.9318  |               |       20.7602  |\n",
            "|          |   eval  |     0.9790  |   0.9318  |       0.9318  |       20.9231  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      31  |      0  |     0.7240  |   0.6237  |               |        2.6763  |\n",
            "|          |      1  |     0.8185  |   0.7245  |               |        5.3629  |\n",
            "|          |      2  |     0.8545  |   0.7727  |               |        8.0491  |\n",
            "|          |      3  |     0.8800  |   0.8376  |               |       10.5712  |\n",
            "|          |      4  |     0.9100  |   0.8781  |               |       13.0987  |\n",
            "|          |      5  |     0.9305  |   0.9059  |               |       15.6208  |\n",
            "|          |      6  |     0.9570  |   0.9253  |               |       18.1373  |\n",
            "|          |      7  |     0.9780  |   0.9328  |               |       20.6563  |\n",
            "|          |   eval  |     0.9780  |   0.9328  |       0.9328  |       20.8171  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      32  |      0  |     0.7110  |   0.6396  |               |        2.6715  |\n",
            "|          |      1  |     0.8165  |   0.7176  |               |        5.3602  |\n",
            "|          |      2  |     0.8685  |   0.7947  |               |        8.0502  |\n",
            "|          |      3  |     0.8795  |   0.8630  |               |       10.5943  |\n",
            "|          |      4  |     0.8860  |   0.8801  |               |       13.1262  |\n",
            "|          |      5  |     0.9350  |   0.8974  |               |       15.6392  |\n",
            "|          |      6  |     0.9580  |   0.9205  |               |       18.1691  |\n",
            "|          |      7  |     0.9740  |   0.9299  |               |       20.6852  |\n",
            "|          |   eval  |     0.9740  |   0.9299  |       0.9299  |       20.8449  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      33  |      0  |     0.7385  |   0.5723  |               |        2.6632  |\n",
            "|          |      1  |     0.8105  |   0.7084  |               |        5.3501  |\n",
            "|          |      2  |     0.8415  |   0.7098  |               |        8.0403  |\n",
            "|          |      3  |     0.8795  |   0.8500  |               |       10.5783  |\n",
            "|          |      4  |     0.9150  |   0.8921  |               |       13.1078  |\n",
            "|          |      5  |     0.9295  |   0.9076  |               |       15.6234  |\n",
            "|          |      6  |     0.9610  |   0.9232  |               |       18.1542  |\n",
            "|          |      7  |     0.9800  |   0.9327  |               |       20.6682  |\n",
            "|          |   eval  |     0.9800  |   0.9327  |       0.9327  |       20.8300  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      34  |      0  |     0.7245  |   0.6084  |               |        2.6747  |\n",
            "|          |      1  |     0.8255  |   0.7640  |               |        5.3651  |\n",
            "|          |      2  |     0.8595  |   0.8024  |               |        8.0464  |\n",
            "|          |      3  |     0.8635  |   0.8409  |               |       10.5918  |\n",
            "|          |      4  |     0.9050  |   0.8637  |               |       13.1058  |\n",
            "|          |      5  |     0.9245  |   0.9120  |               |       15.6218  |\n",
            "|          |      6  |     0.9595  |   0.9200  |               |       18.1353  |\n",
            "|          |      7  |     0.9760  |   0.9303  |               |       20.6475  |\n",
            "|          |   eval  |     0.9760  |   0.9303  |       0.9303  |       20.8108  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      35  |      0  |     0.7455  |   0.5397  |               |        2.6486  |\n",
            "|          |      1  |     0.8255  |   0.6734  |               |        5.3319  |\n",
            "|          |      2  |     0.8550  |   0.8023  |               |        8.0183  |\n",
            "|          |      3  |     0.8780  |   0.8114  |               |       10.5515  |\n",
            "|          |      4  |     0.9165  |   0.8678  |               |       13.0737  |\n",
            "|          |      5  |     0.9335  |   0.9095  |               |       15.5984  |\n",
            "|          |      6  |     0.9510  |   0.9196  |               |       18.1134  |\n",
            "|          |      7  |     0.9790  |   0.9330  |               |       20.6256  |\n",
            "|          |   eval  |     0.9790  |   0.9330  |       0.9330  |       20.7869  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      36  |      0  |     0.7270  |   0.6834  |               |        2.6656  |\n",
            "|          |      1  |     0.8240  |   0.7556  |               |        5.3474  |\n",
            "|          |      2  |     0.8480  |   0.8163  |               |        8.0331  |\n",
            "|          |      3  |     0.8875  |   0.8529  |               |       10.5631  |\n",
            "|          |      4  |     0.8975  |   0.8613  |               |       13.0943  |\n",
            "|          |      5  |     0.9205  |   0.9088  |               |       15.6259  |\n",
            "|          |      6  |     0.9440  |   0.9160  |               |       18.1420  |\n",
            "|          |      7  |     0.9800  |   0.9299  |               |       20.6700  |\n",
            "|          |   eval  |     0.9800  |   0.9299  |       0.9299  |       20.8337  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      37  |      0  |     0.7465  |   0.6204  |               |        2.6639  |\n",
            "|          |      1  |     0.7930  |   0.7660  |               |        5.3526  |\n",
            "|          |      2  |     0.8480  |   0.7910  |               |        8.0358  |\n",
            "|          |      3  |     0.8945  |   0.8518  |               |       10.5703  |\n",
            "|          |      4  |     0.9015  |   0.8618  |               |       13.0896  |\n",
            "|          |      5  |     0.9265  |   0.8875  |               |       15.6208  |\n",
            "|          |      6  |     0.9585  |   0.9279  |               |       18.1382  |\n",
            "|          |      7  |     0.9760  |   0.9328  |               |       20.6572  |\n",
            "|          |   eval  |     0.9760  |   0.9328  |       0.9328  |       20.8193  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      38  |      0  |     0.7470  |   0.6299  |               |        2.6638  |\n",
            "|          |      1  |     0.8065  |   0.7471  |               |        5.3491  |\n",
            "|          |      2  |     0.8655  |   0.7017  |               |        8.0362  |\n",
            "|          |      3  |     0.8770  |   0.8531  |               |       10.5598  |\n",
            "|          |      4  |     0.8995  |   0.8875  |               |       13.0721  |\n",
            "|          |      5  |     0.9265  |   0.9095  |               |       15.5823  |\n",
            "|          |      6  |     0.9525  |   0.9246  |               |       18.0930  |\n",
            "|          |      7  |     0.9800  |   0.9347  |               |       20.6088  |\n",
            "|          |   eval  |     0.9800  |   0.9347  |       0.9347  |       20.7699  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      39  |      0  |     0.7250  |   0.6820  |               |        2.6611  |\n",
            "|          |      1  |     0.8280  |   0.7637  |               |        5.3405  |\n",
            "|          |      2  |     0.8385  |   0.8116  |               |        8.0185  |\n",
            "|          |      3  |     0.8800  |   0.8356  |               |       10.5551  |\n",
            "|          |      4  |     0.9090  |   0.8803  |               |       13.0650  |\n",
            "|          |      5  |     0.9235  |   0.9108  |               |       15.5959  |\n",
            "|          |      6  |     0.9505  |   0.9222  |               |       18.1121  |\n",
            "|          |      7  |     0.9740  |   0.9318  |               |       20.6241  |\n",
            "|          |   eval  |     0.9740  |   0.9318  |       0.9318  |       20.7853  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      40  |      0  |     0.7020  |   0.6510  |               |        2.6720  |\n",
            "|          |      1  |     0.8230  |   0.7702  |               |        5.3500  |\n",
            "|          |      2  |     0.8360  |   0.8109  |               |        8.0321  |\n",
            "|          |      3  |     0.8865  |   0.8582  |               |       10.5629  |\n",
            "|          |      4  |     0.9115  |   0.8606  |               |       13.0930  |\n",
            "|          |      5  |     0.9230  |   0.9020  |               |       15.6088  |\n",
            "|          |      6  |     0.9475  |   0.9247  |               |       18.1234  |\n",
            "|          |      7  |     0.9775  |   0.9334  |               |       20.6596  |\n",
            "|          |   eval  |     0.9775  |   0.9334  |       0.9334  |       20.8244  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      41  |      0  |     0.7350  |   0.5675  |               |        2.6673  |\n",
            "|          |      1  |     0.8255  |   0.7459  |               |        5.3522  |\n",
            "|          |      2  |     0.8490  |   0.7642  |               |        8.0464  |\n",
            "|          |      3  |     0.8775  |   0.7547  |               |       10.5799  |\n",
            "|          |      4  |     0.9035  |   0.8723  |               |       13.1157  |\n",
            "|          |      5  |     0.9385  |   0.9063  |               |       15.6521  |\n",
            "|          |      6  |     0.9610  |   0.9273  |               |       18.1689  |\n",
            "|          |      7  |     0.9760  |   0.9345  |               |       20.7223  |\n",
            "|          |   eval  |     0.9760  |   0.9345  |       0.9345  |       20.8857  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      42  |      0  |     0.7210  |   0.6101  |               |        2.6813  |\n",
            "|          |      1  |     0.8310  |   0.7365  |               |        5.3727  |\n",
            "|          |      2  |     0.8505  |   0.8196  |               |        8.0554  |\n",
            "|          |      3  |     0.8710  |   0.8434  |               |       10.6029  |\n",
            "|          |      4  |     0.9045  |   0.8702  |               |       13.1302  |\n",
            "|          |      5  |     0.9165  |   0.8982  |               |       15.6820  |\n",
            "|          |      6  |     0.9490  |   0.9251  |               |       18.2156  |\n",
            "|          |      7  |     0.9765  |   0.9307  |               |       20.7331  |\n",
            "|          |   eval  |     0.9765  |   0.9307  |       0.9307  |       20.8958  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      43  |      0  |     0.7235  |   0.6603  |               |        2.6694  |\n",
            "|          |      1  |     0.8285  |   0.6850  |               |        5.3639  |\n",
            "|          |      2  |     0.8515  |   0.8273  |               |        8.0550  |\n",
            "|          |      3  |     0.8725  |   0.8471  |               |       10.6086  |\n",
            "|          |      4  |     0.9080  |   0.8779  |               |       13.1446  |\n",
            "|          |      5  |     0.9215  |   0.9087  |               |       15.6816  |\n",
            "|          |      6  |     0.9610  |   0.9220  |               |       18.2206  |\n",
            "|          |      7  |     0.9810  |   0.9324  |               |       20.7544  |\n",
            "|          |   eval  |     0.9810  |   0.9324  |       0.9324  |       20.9144  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      44  |      0  |     0.7280  |   0.5779  |               |        2.6733  |\n",
            "|          |      1  |     0.8085  |   0.7545  |               |        5.3615  |\n",
            "|          |      2  |     0.8665  |   0.8019  |               |        8.0557  |\n",
            "|          |      3  |     0.8745  |   0.8125  |               |       10.5772  |\n",
            "|          |      4  |     0.9065  |   0.8873  |               |       13.1043  |\n",
            "|          |      5  |     0.9230  |   0.8967  |               |       15.6579  |\n",
            "|          |      6  |     0.9550  |   0.9219  |               |       18.1863  |\n",
            "|          |      7  |     0.9790  |   0.9332  |               |       20.7197  |\n",
            "|          |   eval  |     0.9790  |   0.9332  |       0.9332  |       20.8851  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      45  |      0  |     0.7415  |   0.6325  |               |        2.6892  |\n",
            "|          |      1  |     0.8240  |   0.7464  |               |        5.3799  |\n",
            "|          |      2  |     0.8535  |   0.8090  |               |        8.0709  |\n",
            "|          |      3  |     0.8825  |   0.8356  |               |       10.6129  |\n",
            "|          |      4  |     0.9135  |   0.8805  |               |       13.1430  |\n",
            "|          |      5  |     0.9355  |   0.8930  |               |       15.6984  |\n",
            "|          |      6  |     0.9580  |   0.9254  |               |       18.2300  |\n",
            "|          |      7  |     0.9780  |   0.9309  |               |       20.7863  |\n",
            "|          |   eval  |     0.9780  |   0.9309  |       0.9309  |       20.9499  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      46  |      0  |     0.7220  |   0.6519  |               |        2.6920  |\n",
            "|          |      1  |     0.7785  |   0.7299  |               |        5.3915  |\n",
            "|          |      2  |     0.8360  |   0.7815  |               |        8.0953  |\n",
            "|          |      3  |     0.8840  |   0.8388  |               |       10.6360  |\n",
            "|          |      4  |     0.9095  |   0.8713  |               |       13.1882  |\n",
            "|          |      5  |     0.9315  |   0.9106  |               |       15.7436  |\n",
            "|          |      6  |     0.9620  |   0.9205  |               |       18.2810  |\n",
            "|          |      7  |     0.9765  |   0.9318  |               |       20.8331  |\n",
            "|          |   eval  |     0.9765  |   0.9318  |       0.9318  |       20.9949  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      47  |      0  |     0.7500  |   0.6099  |               |        2.6687  |\n",
            "|          |      1  |     0.8280  |   0.7878  |               |        5.3527  |\n",
            "|          |      2  |     0.8505  |   0.8114  |               |        8.0374  |\n",
            "|          |      3  |     0.8820  |   0.8376  |               |       10.5655  |\n",
            "|          |      4  |     0.9105  |   0.8712  |               |       13.0923  |\n",
            "|          |      5  |     0.9355  |   0.9087  |               |       15.6126  |\n",
            "|          |      6  |     0.9570  |   0.9237  |               |       18.1291  |\n",
            "|          |      7  |     0.9785  |   0.9308  |               |       20.6410  |\n",
            "|          |   eval  |     0.9785  |   0.9308  |       0.9308  |       20.8006  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      48  |      0  |     0.7120  |   0.6456  |               |        2.6613  |\n",
            "|          |      1  |     0.7985  |   0.7388  |               |        5.3365  |\n",
            "|          |      2  |     0.8495  |   0.7853  |               |        8.0085  |\n",
            "|          |      3  |     0.8725  |   0.8288  |               |       10.5207  |\n",
            "|          |      4  |     0.8975  |   0.8783  |               |       13.0284  |\n",
            "|          |      5  |     0.9265  |   0.9059  |               |       15.5255  |\n",
            "|          |      6  |     0.9575  |   0.9201  |               |       18.0166  |\n",
            "|          |      7  |     0.9760  |   0.9320  |               |       20.5233  |\n",
            "|          |   eval  |     0.9760  |   0.9320  |       0.9320  |       20.6840  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      49  |      0  |     0.7105  |   0.6291  |               |        2.6554  |\n",
            "|          |      1  |     0.8015  |   0.7327  |               |        5.3245  |\n",
            "|          |      2  |     0.8315  |   0.6620  |               |        8.0023  |\n",
            "|          |      3  |     0.8690  |   0.8313  |               |       10.5188  |\n",
            "|          |      4  |     0.9050  |   0.8740  |               |       13.0308  |\n",
            "|          |      5  |     0.9265  |   0.8989  |               |       15.5479  |\n",
            "|          |      6  |     0.9605  |   0.9226  |               |       18.0587  |\n",
            "|          |      7  |     0.9730  |   0.9300  |               |       20.5715  |\n",
            "|          |   eval  |     0.9730  |   0.9300  |       0.9300  |       20.7319  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      50  |      0  |     0.7305  |   0.6264  |               |        2.6712  |\n",
            "|          |      1  |     0.8100  |   0.7138  |               |        5.3554  |\n",
            "|          |      2  |     0.8450  |   0.7554  |               |        8.0360  |\n",
            "|          |      3  |     0.8810  |   0.8115  |               |       10.5556  |\n",
            "|          |      4  |     0.8960  |   0.8885  |               |       13.0678  |\n",
            "|          |      5  |     0.9265  |   0.9013  |               |       15.5812  |\n",
            "|          |      6  |     0.9515  |   0.9229  |               |       18.0935  |\n",
            "|          |      7  |     0.9760  |   0.9298  |               |       20.6046  |\n",
            "|          |   eval  |     0.9760  |   0.9298  |       0.9298  |       20.7672  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      51  |      0  |     0.7270  |   0.5968  |               |        2.6647  |\n",
            "|          |      1  |     0.7970  |   0.4867  |               |        5.3452  |\n",
            "|          |      2  |     0.8640  |   0.7519  |               |        8.0306  |\n",
            "|          |      3  |     0.8695  |   0.7164  |               |       10.5455  |\n",
            "|          |      4  |     0.9165  |   0.8796  |               |       13.0558  |\n",
            "|          |      5  |     0.9365  |   0.9018  |               |       15.5689  |\n",
            "|          |      6  |     0.9590  |   0.9256  |               |       18.0801  |\n",
            "|          |      7  |     0.9775  |   0.9314  |               |       20.5942  |\n",
            "|          |   eval  |     0.9775  |   0.9314  |       0.9314  |       20.7549  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      52  |      0  |     0.7290  |   0.6116  |               |        2.6527  |\n",
            "|          |      1  |     0.8195  |   0.7692  |               |        5.3390  |\n",
            "|          |      2  |     0.8565  |   0.7337  |               |        8.0244  |\n",
            "|          |      3  |     0.8715  |   0.8532  |               |       10.5450  |\n",
            "|          |      4  |     0.8880  |   0.8868  |               |       13.0574  |\n",
            "|          |      5  |     0.9435  |   0.9041  |               |       15.5907  |\n",
            "|          |      6  |     0.9585  |   0.9234  |               |       18.1096  |\n",
            "|          |      7  |     0.9775  |   0.9322  |               |       20.6452  |\n",
            "|          |   eval  |     0.9775  |   0.9322  |       0.9322  |       20.8072  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      53  |      0  |     0.7240  |   0.4517  |               |        2.6794  |\n",
            "|          |      1  |     0.8125  |   0.7344  |               |        5.3686  |\n",
            "|          |      2  |     0.8465  |   0.7990  |               |        8.0611  |\n",
            "|          |      3  |     0.8785  |   0.8157  |               |       10.5988  |\n",
            "|          |      4  |     0.9065  |   0.8913  |               |       13.1249  |\n",
            "|          |      5  |     0.9360  |   0.9045  |               |       15.6576  |\n",
            "|          |      6  |     0.9585  |   0.9226  |               |       18.1897  |\n",
            "|          |      7  |     0.9730  |   0.9328  |               |       20.7223  |\n",
            "|          |   eval  |     0.9730  |   0.9328  |       0.9328  |       20.8845  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      54  |      0  |     0.7165  |   0.6743  |               |        2.6830  |\n",
            "|          |      1  |     0.8030  |   0.6242  |               |        5.3777  |\n",
            "|          |      2  |     0.8385  |   0.7954  |               |        8.0789  |\n",
            "|          |      3  |     0.8850  |   0.8662  |               |       10.6157  |\n",
            "|          |      4  |     0.9045  |   0.8903  |               |       13.1462  |\n",
            "|          |      5  |     0.9330  |   0.8996  |               |       15.6958  |\n",
            "|          |      6  |     0.9525  |   0.9221  |               |       18.2246  |\n",
            "|          |      7  |     0.9780  |   0.9326  |               |       20.7793  |\n",
            "|          |   eval  |     0.9780  |   0.9326  |       0.9326  |       20.9424  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      55  |      0  |     0.6795  |   0.6497  |               |        2.6793  |\n",
            "|          |      1  |     0.8160  |   0.6767  |               |        5.3734  |\n",
            "|          |      2  |     0.8540  |   0.8011  |               |        8.0717  |\n",
            "|          |      3  |     0.8630  |   0.8363  |               |       10.6185  |\n",
            "|          |      4  |     0.9095  |   0.8705  |               |       13.1497  |\n",
            "|          |      5  |     0.9315  |   0.9044  |               |       15.7082  |\n",
            "|          |      6  |     0.9515  |   0.9170  |               |       18.2424  |\n",
            "|          |      7  |     0.9760  |   0.9327  |               |       20.7771  |\n",
            "|          |   eval  |     0.9760  |   0.9327  |       0.9327  |       20.9389  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      56  |      0  |     0.7550  |   0.6812  |               |        2.6894  |\n",
            "|          |      1  |     0.8095  |   0.7443  |               |        5.3848  |\n",
            "|          |      2  |     0.8485  |   0.8022  |               |        8.0745  |\n",
            "|          |      3  |     0.8760  |   0.8447  |               |       10.6215  |\n",
            "|          |      4  |     0.8875  |   0.8684  |               |       13.1512  |\n",
            "|          |      5  |     0.9295  |   0.9071  |               |       15.6820  |\n",
            "|          |      6  |     0.9500  |   0.9208  |               |       18.2168  |\n",
            "|          |      7  |     0.9695  |   0.9314  |               |       20.7534  |\n",
            "|          |   eval  |     0.9695  |   0.9314  |       0.9314  |       20.9162  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      57  |      0  |     0.7465  |   0.5932  |               |        2.6729  |\n",
            "|          |      1  |     0.8170  |   0.6618  |               |        5.3677  |\n",
            "|          |      2  |     0.8715  |   0.8328  |               |        8.0563  |\n",
            "|          |      3  |     0.8900  |   0.8341  |               |       10.5853  |\n",
            "|          |      4  |     0.9080  |   0.8813  |               |       13.1021  |\n",
            "|          |      5  |     0.9335  |   0.9040  |               |       15.6199  |\n",
            "|          |      6  |     0.9485  |   0.9156  |               |       18.1307  |\n",
            "|          |      7  |     0.9780  |   0.9297  |               |       20.6580  |\n",
            "|          |   eval  |     0.9780  |   0.9297  |       0.9297  |       20.8198  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      58  |      0  |     0.7230  |   0.5543  |               |        2.6674  |\n",
            "|          |      1  |     0.8265  |   0.7180  |               |        5.3490  |\n",
            "|          |      2  |     0.8510  |   0.7750  |               |        8.0338  |\n",
            "|          |      3  |     0.8895  |   0.8503  |               |       10.5590  |\n",
            "|          |      4  |     0.8975  |   0.8586  |               |       13.0759  |\n",
            "|          |      5  |     0.9390  |   0.8987  |               |       15.5904  |\n",
            "|          |      6  |     0.9515  |   0.9271  |               |       18.1038  |\n",
            "|          |      7  |     0.9750  |   0.9326  |               |       20.6312  |\n",
            "|          |   eval  |     0.9750  |   0.9326  |       0.9326  |       20.7904  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      59  |      0  |     0.7340  |   0.6785  |               |        2.6745  |\n",
            "|          |      1  |     0.8005  |   0.6260  |               |        5.3565  |\n",
            "|          |      2  |     0.8555  |   0.8150  |               |        8.0370  |\n",
            "|          |      3  |     0.8755  |   0.8379  |               |       10.5553  |\n",
            "|          |      4  |     0.9050  |   0.8703  |               |       13.0698  |\n",
            "|          |      5  |     0.9255  |   0.9031  |               |       15.5851  |\n",
            "|          |      6  |     0.9535  |   0.9234  |               |       18.0951  |\n",
            "|          |      7  |     0.9785  |   0.9346  |               |       20.6089  |\n",
            "|          |   eval  |     0.9785  |   0.9346  |       0.9346  |       20.7685  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      60  |      0  |     0.7200  |   0.6136  |               |        2.6507  |\n",
            "|          |      1  |     0.8150  |   0.7457  |               |        5.3341  |\n",
            "|          |      2  |     0.8580  |   0.8024  |               |        8.0137  |\n",
            "|          |      3  |     0.8690  |   0.8130  |               |       10.5256  |\n",
            "|          |      4  |     0.9030  |   0.8805  |               |       13.0325  |\n",
            "|          |      5  |     0.9290  |   0.9035  |               |       15.5449  |\n",
            "|          |      6  |     0.9540  |   0.9221  |               |       18.0551  |\n",
            "|          |      7  |     0.9765  |   0.9312  |               |       20.5690  |\n",
            "|          |   eval  |     0.9765  |   0.9312  |       0.9312  |       20.7312  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      61  |      0  |     0.7240  |   0.7015  |               |        2.6583  |\n",
            "|          |      1  |     0.8275  |   0.7453  |               |        5.3348  |\n",
            "|          |      2  |     0.8495  |   0.7719  |               |        8.0106  |\n",
            "|          |      3  |     0.8890  |   0.8479  |               |       10.5280  |\n",
            "|          |      4  |     0.8965  |   0.8684  |               |       13.0343  |\n",
            "|          |      5  |     0.9375  |   0.9005  |               |       15.5563  |\n",
            "|          |      6  |     0.9585  |   0.9202  |               |       18.0659  |\n",
            "|          |      7  |     0.9735  |   0.9261  |               |       20.5763  |\n",
            "|          |   eval  |     0.9735  |   0.9261  |       0.9261  |       20.7377  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      62  |      0  |     0.7340  |   0.5851  |               |        2.6649  |\n",
            "|          |      1  |     0.7970  |   0.7141  |               |        5.3385  |\n",
            "|          |      2  |     0.8620  |   0.7724  |               |        8.0157  |\n",
            "|          |      3  |     0.8755  |   0.8362  |               |       10.5385  |\n",
            "|          |      4  |     0.8930  |   0.8697  |               |       13.0509  |\n",
            "|          |      5  |     0.9415  |   0.8950  |               |       15.5729  |\n",
            "|          |      6  |     0.9565  |   0.9201  |               |       18.0836  |\n",
            "|          |      7  |     0.9730  |   0.9302  |               |       20.5948  |\n",
            "|          |   eval  |     0.9730  |   0.9302  |       0.9302  |       20.7548  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      63  |      0  |     0.7035  |   0.6189  |               |        2.6608  |\n",
            "|          |      1  |     0.8285  |   0.7438  |               |        5.3404  |\n",
            "|          |      2  |     0.8480  |   0.7718  |               |        8.0116  |\n",
            "|          |      3  |     0.8885  |   0.8371  |               |       10.5315  |\n",
            "|          |      4  |     0.9105  |   0.8621  |               |       13.0342  |\n",
            "|          |      5  |     0.9330  |   0.9036  |               |       15.5440  |\n",
            "|          |      6  |     0.9520  |   0.9206  |               |       18.0512  |\n",
            "|          |      7  |     0.9750  |   0.9303  |               |       20.5629  |\n",
            "|          |   eval  |     0.9750  |   0.9303  |       0.9303  |       20.7224  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      64  |      0  |     0.7085  |   0.6867  |               |        2.6587  |\n",
            "|          |      1  |     0.8095  |   0.6910  |               |        5.3411  |\n",
            "|          |      2  |     0.8635  |   0.7638  |               |        8.0206  |\n",
            "|          |      3  |     0.8625  |   0.8206  |               |       10.5432  |\n",
            "|          |      4  |     0.9030  |   0.8875  |               |       13.0594  |\n",
            "|          |      5  |     0.9385  |   0.9060  |               |       15.5863  |\n",
            "|          |      6  |     0.9605  |   0.9169  |               |       18.0993  |\n",
            "|          |      7  |     0.9800  |   0.9328  |               |       20.6112  |\n",
            "|          |   eval  |     0.9800  |   0.9328  |       0.9328  |       20.7724  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      65  |      0  |     0.7365  |   0.6982  |               |        2.6537  |\n",
            "|          |      1  |     0.8060  |   0.6620  |               |        5.3395  |\n",
            "|          |      2  |     0.8475  |   0.7990  |               |        8.0301  |\n",
            "|          |      3  |     0.8760  |   0.8401  |               |       10.5646  |\n",
            "|          |      4  |     0.9090  |   0.8760  |               |       13.0924  |\n",
            "|          |      5  |     0.9400  |   0.9069  |               |       15.6025  |\n",
            "|          |      6  |     0.9505  |   0.9241  |               |       18.1341  |\n",
            "|          |      7  |     0.9720  |   0.9300  |               |       20.6699  |\n",
            "|          |   eval  |     0.9720  |   0.9300  |       0.9300  |       20.8337  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      66  |      0  |     0.7240  |   0.6447  |               |        2.6598  |\n",
            "|          |      1  |     0.8290  |   0.7136  |               |        5.3419  |\n",
            "|          |      2  |     0.8525  |   0.7846  |               |        8.0294  |\n",
            "|          |      3  |     0.8895  |   0.8496  |               |       10.5644  |\n",
            "|          |      4  |     0.9155  |   0.8735  |               |       13.0893  |\n",
            "|          |      5  |     0.9425  |   0.8899  |               |       15.6262  |\n",
            "|          |      6  |     0.9625  |   0.9230  |               |       18.1589  |\n",
            "|          |      7  |     0.9770  |   0.9312  |               |       20.6935  |\n",
            "|          |   eval  |     0.9770  |   0.9312  |       0.9312  |       20.8549  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      67  |      0  |     0.7205  |   0.6249  |               |        2.6619  |\n",
            "|          |      1  |     0.8030  |   0.7153  |               |        5.3559  |\n",
            "|          |      2  |     0.8550  |   0.7701  |               |        8.0468  |\n",
            "|          |      3  |     0.8805  |   0.8299  |               |       10.5989  |\n",
            "|          |      4  |     0.9135  |   0.8894  |               |       13.1375  |\n",
            "|          |      5  |     0.9340  |   0.9043  |               |       15.6768  |\n",
            "|          |      6  |     0.9580  |   0.9240  |               |       18.2153  |\n",
            "|          |      7  |     0.9735  |   0.9314  |               |       20.7460  |\n",
            "|          |   eval  |     0.9735  |   0.9314  |       0.9314  |       20.9061  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      68  |      0  |     0.7305  |   0.6076  |               |        2.6759  |\n",
            "|          |      1  |     0.8325  |   0.7300  |               |        5.3654  |\n",
            "|          |      2  |     0.8550  |   0.7991  |               |        8.0605  |\n",
            "|          |      3  |     0.8965  |   0.8190  |               |       10.6015  |\n",
            "|          |      4  |     0.9070  |   0.8704  |               |       13.1297  |\n",
            "|          |      5  |     0.9255  |   0.8930  |               |       15.6820  |\n",
            "|          |      6  |     0.9575  |   0.9191  |               |       18.2139  |\n",
            "|          |      7  |     0.9795  |   0.9319  |               |       20.7656  |\n",
            "|          |   eval  |     0.9795  |   0.9319  |       0.9319  |       20.9294  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      69  |      0  |     0.7245  |   0.6570  |               |        2.6780  |\n",
            "|          |      1  |     0.8240  |   0.7421  |               |        5.3790  |\n",
            "|          |      2  |     0.8405  |   0.7886  |               |        8.0839  |\n",
            "|          |      3  |     0.8755  |   0.8439  |               |       10.6246  |\n",
            "|          |      4  |     0.9115  |   0.8740  |               |       13.1557  |\n",
            "|          |      5  |     0.9345  |   0.8987  |               |       15.7056  |\n",
            "|          |      6  |     0.9555  |   0.9249  |               |       18.2586  |\n",
            "|          |      7  |     0.9845  |   0.9335  |               |       20.8153  |\n",
            "|          |   eval  |     0.9845  |   0.9335  |       0.9335  |       20.9793  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      70  |      0  |     0.7280  |   0.5186  |               |        2.6781  |\n",
            "|          |      1  |     0.7755  |   0.7301  |               |        5.3716  |\n",
            "|          |      2  |     0.8520  |   0.8049  |               |        8.0718  |\n",
            "|          |      3  |     0.8935  |   0.8321  |               |       10.6234  |\n",
            "|          |      4  |     0.9105  |   0.8660  |               |       13.1549  |\n",
            "|          |      5  |     0.9325  |   0.9075  |               |       15.7125  |\n",
            "|          |      6  |     0.9600  |   0.9211  |               |       18.2487  |\n",
            "|          |      7  |     0.9790  |   0.9319  |               |       20.7857  |\n",
            "|          |   eval  |     0.9790  |   0.9319  |       0.9319  |       20.9482  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      71  |      0  |     0.7170  |   0.6927  |               |        2.6800  |\n",
            "|          |      1  |     0.8255  |   0.7081  |               |        5.3746  |\n",
            "|          |      2  |     0.8560  |   0.7921  |               |        8.0791  |\n",
            "|          |      3  |     0.8800  |   0.8646  |               |       10.6269  |\n",
            "|          |      4  |     0.9135  |   0.8705  |               |       13.1582  |\n",
            "|          |      5  |     0.9310  |   0.9062  |               |       15.7081  |\n",
            "|          |      6  |     0.9500  |   0.9251  |               |       18.2417  |\n",
            "|          |      7  |     0.9745  |   0.9339  |               |       20.7736  |\n",
            "|          |   eval  |     0.9745  |   0.9339  |       0.9339  |       20.9366  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      72  |      0  |     0.7305  |   0.7020  |               |        2.6849  |\n",
            "|          |      1  |     0.8125  |   0.7274  |               |        5.3730  |\n",
            "|          |      2  |     0.8715  |   0.7942  |               |        8.0658  |\n",
            "|          |      3  |     0.8865  |   0.8361  |               |       10.6132  |\n",
            "|          |      4  |     0.8980  |   0.8691  |               |       13.1422  |\n",
            "|          |      5  |     0.9280  |   0.9075  |               |       15.6906  |\n",
            "|          |      6  |     0.9570  |   0.9246  |               |       18.2222  |\n",
            "|          |      7  |     0.9770  |   0.9310  |               |       20.7741  |\n",
            "|          |   eval  |     0.9770  |   0.9310  |       0.9310  |       20.9364  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      73  |      0  |     0.7330  |   0.5305  |               |        2.6794  |\n",
            "|          |      1  |     0.8255  |   0.7800  |               |        5.3756  |\n",
            "|          |      2  |     0.8620  |   0.6879  |               |        8.0699  |\n",
            "|          |      3  |     0.8820  |   0.8252  |               |       10.6152  |\n",
            "|          |      4  |     0.9100  |   0.8857  |               |       13.1466  |\n",
            "|          |      5  |     0.9345  |   0.8992  |               |       15.7059  |\n",
            "|          |      6  |     0.9625  |   0.9220  |               |       18.2407  |\n",
            "|          |      7  |     0.9720  |   0.9319  |               |       20.7760  |\n",
            "|          |   eval  |     0.9720  |   0.9319  |       0.9319  |       20.9401  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      74  |      0  |     0.7340  |   0.6711  |               |        2.6860  |\n",
            "|          |      1  |     0.8145  |   0.7612  |               |        5.3855  |\n",
            "|          |      2  |     0.8515  |   0.7940  |               |        8.0824  |\n",
            "|          |      3  |     0.8685  |   0.8263  |               |       10.6248  |\n",
            "|          |      4  |     0.9025  |   0.8531  |               |       13.1518  |\n",
            "|          |      5  |     0.9280  |   0.8983  |               |       15.7054  |\n",
            "|          |      6  |     0.9545  |   0.9192  |               |       18.2360  |\n",
            "|          |      7  |     0.9745  |   0.9353  |               |       20.7883  |\n",
            "|          |   eval  |     0.9745  |   0.9353  |       0.9353  |       20.9536  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      75  |      0  |     0.7105  |   0.6333  |               |        2.7267  |\n",
            "|          |      1  |     0.7915  |   0.6763  |               |        5.4261  |\n",
            "|          |      2  |     0.8655  |   0.8147  |               |        8.1213  |\n",
            "|          |      3  |     0.8740  |   0.8246  |               |       10.6569  |\n",
            "|          |      4  |     0.9055  |   0.8688  |               |       13.1892  |\n",
            "|          |      5  |     0.9310  |   0.9074  |               |       15.7393  |\n",
            "|          |      6  |     0.9620  |   0.9188  |               |       18.2711  |\n",
            "|          |      7  |     0.9795  |   0.9302  |               |       20.8215  |\n",
            "|          |   eval  |     0.9795  |   0.9302  |       0.9302  |       20.9859  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      76  |      0  |     0.7155  |   0.5387  |               |        2.6895  |\n",
            "|          |      1  |     0.8025  |   0.7218  |               |        5.3863  |\n",
            "|          |      2  |     0.8550  |   0.8182  |               |        8.0862  |\n",
            "|          |      3  |     0.8805  |   0.8518  |               |       10.6238  |\n",
            "|          |      4  |     0.9075  |   0.8810  |               |       13.1544  |\n",
            "|          |      5  |     0.9325  |   0.9123  |               |       15.7058  |\n",
            "|          |      6  |     0.9580  |   0.9213  |               |       18.2435  |\n",
            "|          |      7  |     0.9835  |   0.9340  |               |       20.7992  |\n",
            "|          |   eval  |     0.9835  |   0.9340  |       0.9340  |       20.9625  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      77  |      0  |     0.7225  |   0.7090  |               |        2.6850  |\n",
            "|          |      1  |     0.8065  |   0.7050  |               |        5.3794  |\n",
            "|          |      2  |     0.8655  |   0.8075  |               |        8.0844  |\n",
            "|          |      3  |     0.8835  |   0.8647  |               |       10.6373  |\n",
            "|          |      4  |     0.9055  |   0.8706  |               |       13.1666  |\n",
            "|          |      5  |     0.9260  |   0.9023  |               |       15.7169  |\n",
            "|          |      6  |     0.9600  |   0.9221  |               |       18.2486  |\n",
            "|          |      7  |     0.9810  |   0.9291  |               |       20.7825  |\n",
            "|          |   eval  |     0.9810  |   0.9291  |       0.9291  |       20.9452  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      78  |      0  |     0.7460  |   0.5393  |               |        2.6884  |\n",
            "|          |      1  |     0.8085  |   0.7627  |               |        5.3831  |\n",
            "|          |      2  |     0.8570  |   0.7925  |               |        8.0824  |\n",
            "|          |      3  |     0.8720  |   0.8561  |               |       10.6358  |\n",
            "|          |      4  |     0.9030  |   0.8594  |               |       13.1834  |\n",
            "|          |      5  |     0.9280  |   0.9034  |               |       15.7343  |\n",
            "|          |      6  |     0.9525  |   0.9264  |               |       18.2658  |\n",
            "|          |      7  |     0.9730  |   0.9309  |               |       20.8185  |\n",
            "|          |   eval  |     0.9730  |   0.9309  |       0.9309  |       20.9803  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      79  |      0  |     0.7275  |   0.4128  |               |        2.6682  |\n",
            "|          |      1  |     0.8015  |   0.6633  |               |        5.3633  |\n",
            "|          |      2  |     0.8450  |   0.8075  |               |        8.0555  |\n",
            "|          |      3  |     0.8815  |   0.8171  |               |       10.6101  |\n",
            "|          |      4  |     0.9105  |   0.8574  |               |       13.1401  |\n",
            "|          |      5  |     0.9300  |   0.9013  |               |       15.6769  |\n",
            "|          |      6  |     0.9565  |   0.9209  |               |       18.2144  |\n",
            "|          |      7  |     0.9780  |   0.9304  |               |       20.7497  |\n",
            "|          |   eval  |     0.9780  |   0.9304  |       0.9304  |       20.9145  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      80  |      0  |     0.7050  |   0.6032  |               |        2.6853  |\n",
            "|          |      1  |     0.8245  |   0.7318  |               |        5.3671  |\n",
            "|          |      2  |     0.8470  |   0.7866  |               |        8.0601  |\n",
            "|          |      3  |     0.8775  |   0.8771  |               |       10.5810  |\n",
            "|          |      4  |     0.9050  |   0.8717  |               |       13.1063  |\n",
            "|          |      5  |     0.9385  |   0.9011  |               |       15.6397  |\n",
            "|          |      6  |     0.9540  |   0.9237  |               |       18.1728  |\n",
            "|          |      7  |     0.9815  |   0.9310  |               |       20.6994  |\n",
            "|          |   eval  |     0.9815  |   0.9310  |       0.9310  |       20.8620  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      81  |      0  |     0.7330  |   0.5078  |               |        2.6684  |\n",
            "|          |      1  |     0.8320  |   0.7482  |               |        5.3608  |\n",
            "|          |      2  |     0.8615  |   0.8020  |               |        8.0470  |\n",
            "|          |      3  |     0.8705  |   0.8160  |               |       10.5913  |\n",
            "|          |      4  |     0.9150  |   0.8757  |               |       13.1237  |\n",
            "|          |      5  |     0.9295  |   0.9094  |               |       15.6571  |\n",
            "|          |      6  |     0.9625  |   0.9232  |               |       18.1785  |\n",
            "|          |      7  |     0.9710  |   0.9299  |               |       20.6919  |\n",
            "|          |   eval  |     0.9710  |   0.9299  |       0.9299  |       20.8525  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      82  |      0  |     0.7330  |   0.4971  |               |        2.6708  |\n",
            "|          |      1  |     0.8220  |   0.6300  |               |        5.3655  |\n",
            "|          |      2  |     0.8540  |   0.8156  |               |        8.0509  |\n",
            "|          |      3  |     0.8860  |   0.8113  |               |       10.5753  |\n",
            "|          |      4  |     0.9070  |   0.8783  |               |       13.0886  |\n",
            "|          |      5  |     0.9320  |   0.8821  |               |       15.6045  |\n",
            "|          |      6  |     0.9600  |   0.9225  |               |       18.1018  |\n",
            "|          |      7  |     0.9840  |   0.9279  |               |       20.6152  |\n",
            "|          |   eval  |     0.9840  |   0.9279  |       0.9279  |       20.7755  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      83  |      0  |     0.7200  |   0.5888  |               |        2.6716  |\n",
            "|          |      1  |     0.8145  |   0.6121  |               |        5.3500  |\n",
            "|          |      2  |     0.8400  |   0.7965  |               |        8.0294  |\n",
            "|          |      3  |     0.8740  |   0.8483  |               |       10.5483  |\n",
            "|          |      4  |     0.9060  |   0.8842  |               |       13.0570  |\n",
            "|          |      5  |     0.9300  |   0.8991  |               |       15.5914  |\n",
            "|          |      6  |     0.9495  |   0.9252  |               |       18.1052  |\n",
            "|          |      7  |     0.9780  |   0.9301  |               |       20.6373  |\n",
            "|          |   eval  |     0.9780  |   0.9301  |       0.9301  |       20.8009  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      84  |      0  |     0.7155  |   0.6331  |               |        2.6715  |\n",
            "|          |      1  |     0.8190  |   0.6536  |               |        5.3493  |\n",
            "|          |      2  |     0.8500  |   0.8184  |               |        8.0326  |\n",
            "|          |      3  |     0.8730  |   0.8303  |               |       10.5534  |\n",
            "|          |      4  |     0.9235  |   0.8652  |               |       13.0612  |\n",
            "|          |      5  |     0.9270  |   0.9153  |               |       15.5753  |\n",
            "|          |      6  |     0.9460  |   0.9215  |               |       18.0842  |\n",
            "|          |      7  |     0.9790  |   0.9325  |               |       20.5972  |\n",
            "|          |   eval  |     0.9790  |   0.9325  |       0.9325  |       20.7587  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      85  |      0  |     0.7090  |   0.5900  |               |        2.6634  |\n",
            "|          |      1  |     0.8170  |   0.7753  |               |        5.3473  |\n",
            "|          |      2  |     0.8420  |   0.7642  |               |        8.0258  |\n",
            "|          |      3  |     0.8860  |   0.8335  |               |       10.5476  |\n",
            "|          |      4  |     0.9000  |   0.8767  |               |       13.0582  |\n",
            "|          |      5  |     0.9365  |   0.9036  |               |       15.5777  |\n",
            "|          |      6  |     0.9520  |   0.9199  |               |       18.0900  |\n",
            "|          |      7  |     0.9785  |   0.9293  |               |       20.6028  |\n",
            "|          |   eval  |     0.9785  |   0.9293  |       0.9293  |       20.7643  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      86  |      0  |     0.7215  |   0.3240  |               |        2.6631  |\n",
            "|          |      1  |     0.7890  |   0.6801  |               |        5.3488  |\n",
            "|          |      2  |     0.8755  |   0.8202  |               |        8.0274  |\n",
            "|          |      3  |     0.8805  |   0.8495  |               |       10.5606  |\n",
            "|          |      4  |     0.8870  |   0.8942  |               |       13.0666  |\n",
            "|          |      5  |     0.9325  |   0.9076  |               |       15.5896  |\n",
            "|          |      6  |     0.9555  |   0.9192  |               |       18.1020  |\n",
            "|          |      7  |     0.9745  |   0.9289  |               |       20.6032  |\n",
            "|          |   eval  |     0.9745  |   0.9289  |       0.9289  |       20.7648  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      87  |      0  |     0.7410  |   0.5689  |               |        2.6589  |\n",
            "|          |      1  |     0.8090  |   0.6479  |               |        5.3368  |\n",
            "|          |      2  |     0.8510  |   0.8039  |               |        8.0049  |\n",
            "|          |      3  |     0.8825  |   0.8368  |               |       10.5350  |\n",
            "|          |      4  |     0.9095  |   0.8780  |               |       13.0435  |\n",
            "|          |      5  |     0.9275  |   0.9078  |               |       15.5534  |\n",
            "|          |      6  |     0.9520  |   0.9248  |               |       18.0577  |\n",
            "|          |      7  |     0.9770  |   0.9316  |               |       20.5677  |\n",
            "|          |   eval  |     0.9770  |   0.9316  |       0.9316  |       20.7304  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      88  |      0  |     0.7260  |   0.6531  |               |        2.6581  |\n",
            "|          |      1  |     0.8170  |   0.7008  |               |        5.3311  |\n",
            "|          |      2  |     0.8340  |   0.7533  |               |        8.0076  |\n",
            "|          |      3  |     0.8830  |   0.8583  |               |       10.5193  |\n",
            "|          |      4  |     0.9010  |   0.8679  |               |       13.0312  |\n",
            "|          |      5  |     0.9315  |   0.9122  |               |       15.5408  |\n",
            "|          |      6  |     0.9555  |   0.9202  |               |       18.0503  |\n",
            "|          |      7  |     0.9710  |   0.9301  |               |       20.5612  |\n",
            "|          |   eval  |     0.9710  |   0.9301  |       0.9301  |       20.7234  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      89  |      0  |     0.7375  |   0.5853  |               |        2.6529  |\n",
            "|          |      1  |     0.8190  |   0.7655  |               |        5.3300  |\n",
            "|          |      2  |     0.8385  |   0.7914  |               |        7.9961  |\n",
            "|          |      3  |     0.8855  |   0.8396  |               |       10.5013  |\n",
            "|          |      4  |     0.9055  |   0.8708  |               |       13.0118  |\n",
            "|          |      5  |     0.9220  |   0.9041  |               |       15.5213  |\n",
            "|          |      6  |     0.9580  |   0.9245  |               |       18.0336  |\n",
            "|          |      7  |     0.9780  |   0.9307  |               |       20.5320  |\n",
            "|          |   eval  |     0.9780  |   0.9307  |       0.9307  |       20.6925  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      90  |      0  |     0.7300  |   0.6390  |               |        2.6589  |\n",
            "|          |      1  |     0.7995  |   0.7245  |               |        5.3385  |\n",
            "|          |      2  |     0.8500  |   0.8084  |               |        8.0178  |\n",
            "|          |      3  |     0.8840  |   0.8554  |               |       10.5548  |\n",
            "|          |      4  |     0.9080  |   0.8821  |               |       13.0886  |\n",
            "|          |      5  |     0.9240  |   0.8960  |               |       15.6226  |\n",
            "|          |      6  |     0.9480  |   0.9205  |               |       18.1651  |\n",
            "|          |      7  |     0.9775  |   0.9335  |               |       20.6986  |\n",
            "|          |   eval  |     0.9775  |   0.9335  |       0.9335  |       20.8620  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      91  |      0  |     0.7285  |   0.6236  |               |        2.6900  |\n",
            "|          |      1  |     0.8045  |   0.7065  |               |        5.3749  |\n",
            "|          |      2  |     0.8525  |   0.7789  |               |        8.0650  |\n",
            "|          |      3  |     0.8730  |   0.7952  |               |       10.6127  |\n",
            "|          |      4  |     0.9090  |   0.8449  |               |       13.1438  |\n",
            "|          |      5  |     0.9230  |   0.9043  |               |       15.6967  |\n",
            "|          |      6  |     0.9575  |   0.9216  |               |       18.2322  |\n",
            "|          |      7  |     0.9760  |   0.9305  |               |       20.7814  |\n",
            "|          |   eval  |     0.9760  |   0.9305  |       0.9305  |       20.9427  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      92  |      0  |     0.7185  |   0.6002  |               |        2.6876  |\n",
            "|          |      1  |     0.8225  |   0.7386  |               |        5.3898  |\n",
            "|          |      2  |     0.8545  |   0.7786  |               |        8.0937  |\n",
            "|          |      3  |     0.8780  |   0.8365  |               |       10.6381  |\n",
            "|          |      4  |     0.8960  |   0.8803  |               |       13.1695  |\n",
            "|          |      5  |     0.9220  |   0.8889  |               |       15.7182  |\n",
            "|          |      6  |     0.9570  |   0.9234  |               |       18.2520  |\n",
            "|          |      7  |     0.9750  |   0.9322  |               |       20.8031  |\n",
            "|          |   eval  |     0.9750  |   0.9322  |       0.9322  |       20.9662  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      93  |      0  |     0.7420  |   0.6486  |               |        2.6805  |\n",
            "|          |      1  |     0.8215  |   0.7388  |               |        5.3746  |\n",
            "|          |      2  |     0.8625  |   0.7714  |               |        8.0641  |\n",
            "|          |      3  |     0.8780  |   0.8525  |               |       10.6026  |\n",
            "|          |      4  |     0.9125  |   0.8835  |               |       13.1318  |\n",
            "|          |      5  |     0.9200  |   0.9053  |               |       15.6665  |\n",
            "|          |      6  |     0.9560  |   0.9232  |               |       18.1999  |\n",
            "|          |      7  |     0.9795  |   0.9289  |               |       20.7202  |\n",
            "|          |   eval  |     0.9795  |   0.9289  |       0.9289  |       20.8808  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      94  |      0  |     0.7345  |   0.5532  |               |        2.6692  |\n",
            "|          |      1  |     0.8160  |   0.7394  |               |        5.3623  |\n",
            "|          |      2  |     0.8510  |   0.8183  |               |        8.0510  |\n",
            "|          |      3  |     0.8770  |   0.8190  |               |       10.5943  |\n",
            "|          |      4  |     0.9025  |   0.8838  |               |       13.1259  |\n",
            "|          |      5  |     0.9220  |   0.9081  |               |       15.6421  |\n",
            "|          |      6  |     0.9505  |   0.9208  |               |       18.1567  |\n",
            "|          |      7  |     0.9725  |   0.9354  |               |       20.6744  |\n",
            "|          |   eval  |     0.9725  |   0.9354  |       0.9354  |       20.8348  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      95  |      0  |     0.6900  |   0.6262  |               |        2.6559  |\n",
            "|          |      1  |     0.7935  |   0.7206  |               |        5.3398  |\n",
            "|          |      2  |     0.8375  |   0.7107  |               |        8.0253  |\n",
            "|          |      3  |     0.8875  |   0.8384  |               |       10.5425  |\n",
            "|          |      4  |     0.9085  |   0.8686  |               |       13.0632  |\n",
            "|          |      5  |     0.9235  |   0.9014  |               |       15.5869  |\n",
            "|          |      6  |     0.9475  |   0.9230  |               |       18.0975  |\n",
            "|          |      7  |     0.9750  |   0.9329  |               |       20.6124  |\n",
            "|          |   eval  |     0.9750  |   0.9329  |       0.9329  |       20.7738  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      96  |      0  |     0.7270  |   0.6025  |               |        2.6620  |\n",
            "|          |      1  |     0.8030  |   0.7888  |               |        5.3410  |\n",
            "|          |      2  |     0.8485  |   0.7780  |               |        8.0239  |\n",
            "|          |      3  |     0.8825  |   0.8463  |               |       10.5362  |\n",
            "|          |      4  |     0.8970  |   0.8915  |               |       13.0389  |\n",
            "|          |      5  |     0.9155  |   0.8922  |               |       15.5575  |\n",
            "|          |      6  |     0.9460  |   0.9260  |               |       18.0681  |\n",
            "|          |      7  |     0.9765  |   0.9339  |               |       20.5822  |\n",
            "|          |   eval  |     0.9765  |   0.9339  |       0.9339  |       20.7427  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      97  |      0  |     0.6910  |   0.7210  |               |        2.6493  |\n",
            "|          |      1  |     0.8185  |   0.7877  |               |        5.3309  |\n",
            "|          |      2  |     0.8665  |   0.7539  |               |        8.0096  |\n",
            "|          |      3  |     0.8930  |   0.8469  |               |       10.5228  |\n",
            "|          |      4  |     0.9045  |   0.8518  |               |       13.0347  |\n",
            "|          |      5  |     0.9350  |   0.9117  |               |       15.5473  |\n",
            "|          |      6  |     0.9530  |   0.9242  |               |       18.0552  |\n",
            "|          |      7  |     0.9800  |   0.9332  |               |       20.5654  |\n",
            "|          |   eval  |     0.9800  |   0.9332  |       0.9332  |       20.7252  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      98  |      0  |     0.7240  |   0.6292  |               |        2.6529  |\n",
            "|          |      1  |     0.7985  |   0.7535  |               |        5.3315  |\n",
            "|          |      2  |     0.8690  |   0.7847  |               |        7.9960  |\n",
            "|          |      3  |     0.8835  |   0.8532  |               |       10.5087  |\n",
            "|          |      4  |     0.8990  |   0.8872  |               |       13.0198  |\n",
            "|          |      5  |     0.9330  |   0.9013  |               |       15.5264  |\n",
            "|          |      6  |     0.9625  |   0.9272  |               |       18.0425  |\n",
            "|          |      7  |     0.9755  |   0.9321  |               |       20.5640  |\n",
            "|          |   eval  |     0.9755  |   0.9321  |       0.9321  |       20.7239  |\n",
            "---------------------------------------------------------------------------------\n",
            "|      99  |      0  |     0.7335  |   0.5466  |               |        2.6523  |\n",
            "|          |      1  |     0.8085  |   0.7709  |               |        5.3244  |\n",
            "|          |      2  |     0.8350  |   0.7491  |               |        7.9971  |\n",
            "|          |      3  |     0.8845  |   0.8499  |               |       10.5229  |\n",
            "|          |      4  |     0.9065  |   0.8775  |               |       13.0402  |\n",
            "|          |      5  |     0.9265  |   0.9032  |               |       15.5672  |\n",
            "|          |      6  |     0.9535  |   0.9228  |               |       18.0848  |\n",
            "|          |      7  |     0.9770  |   0.9298  |               |       20.5951  |\n",
            "|          |   eval  |     0.9770  |   0.9298  |       0.9298  |       20.7552  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     100  |      0  |     0.7090  |   0.5948  |               |        2.6518  |\n",
            "|          |      1  |     0.8185  |   0.7193  |               |        5.3391  |\n",
            "|          |      2  |     0.8415  |   0.8227  |               |        8.0213  |\n",
            "|          |      3  |     0.8760  |   0.8464  |               |       10.5471  |\n",
            "|          |      4  |     0.8995  |   0.8657  |               |       13.0775  |\n",
            "|          |      5  |     0.9320  |   0.8991  |               |       15.6131  |\n",
            "|          |      6  |     0.9560  |   0.9202  |               |       18.1267  |\n",
            "|          |      7  |     0.9770  |   0.9332  |               |       20.6447  |\n",
            "|          |   eval  |     0.9770  |   0.9332  |       0.9332  |       20.8051  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     101  |      0  |     0.7160  |   0.6757  |               |        2.6525  |\n",
            "|          |      1  |     0.8040  |   0.6907  |               |        5.3316  |\n",
            "|          |      2  |     0.8405  |   0.7775  |               |        8.0153  |\n",
            "|          |      3  |     0.8735  |   0.8188  |               |       10.5352  |\n",
            "|          |      4  |     0.8980  |   0.8814  |               |       13.0503  |\n",
            "|          |      5  |     0.9305  |   0.9060  |               |       15.5647  |\n",
            "|          |      6  |     0.9605  |   0.9247  |               |       18.0755  |\n",
            "|          |      7  |     0.9735  |   0.9302  |               |       20.5876  |\n",
            "|          |   eval  |     0.9735  |   0.9302  |       0.9302  |       20.7498  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     102  |      0  |     0.7370  |   0.6749  |               |        2.6756  |\n",
            "|          |      1  |     0.8130  |   0.6751  |               |        5.3594  |\n",
            "|          |      2  |     0.8535  |   0.8087  |               |        8.0412  |\n",
            "|          |      3  |     0.8685  |   0.8215  |               |       10.5913  |\n",
            "|          |      4  |     0.9065  |   0.8359  |               |       13.1209  |\n",
            "|          |      5  |     0.9285  |   0.9138  |               |       15.6599  |\n",
            "|          |      6  |     0.9525  |   0.9238  |               |       18.1946  |\n",
            "|          |      7  |     0.9780  |   0.9332  |               |       20.7286  |\n",
            "|          |   eval  |     0.9780  |   0.9332  |       0.9332  |       20.8926  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     103  |      0  |     0.7350  |   0.6184  |               |        2.6733  |\n",
            "|          |      1  |     0.7895  |   0.7031  |               |        5.3630  |\n",
            "|          |      2  |     0.8610  |   0.8218  |               |        8.0508  |\n",
            "|          |      3  |     0.8875  |   0.8443  |               |       10.5962  |\n",
            "|          |      4  |     0.9030  |   0.8712  |               |       13.1077  |\n",
            "|          |      5  |     0.9370  |   0.9032  |               |       15.6393  |\n",
            "|          |      6  |     0.9470  |   0.9250  |               |       18.1726  |\n",
            "|          |      7  |     0.9780  |   0.9317  |               |       20.6901  |\n",
            "|          |   eval  |     0.9780  |   0.9317  |       0.9317  |       20.8520  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     104  |      0  |     0.7495  |   0.5831  |               |        2.6768  |\n",
            "|          |      1  |     0.8070  |   0.7257  |               |        5.3598  |\n",
            "|          |      2  |     0.8310  |   0.7889  |               |        8.0461  |\n",
            "|          |      3  |     0.8810  |   0.8432  |               |       10.5910  |\n",
            "|          |      4  |     0.9140  |   0.8696  |               |       13.1196  |\n",
            "|          |      5  |     0.9320  |   0.9015  |               |       15.6669  |\n",
            "|          |      6  |     0.9570  |   0.9266  |               |       18.2011  |\n",
            "|          |      7  |     0.9765  |   0.9335  |               |       20.7167  |\n",
            "|          |   eval  |     0.9765  |   0.9335  |       0.9335  |       20.8791  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     105  |      0  |     0.7175  |   0.6735  |               |        2.6700  |\n",
            "|          |      1  |     0.8020  |   0.5988  |               |        5.3540  |\n",
            "|          |      2  |     0.8495  |   0.8077  |               |        8.0437  |\n",
            "|          |      3  |     0.8660  |   0.8724  |               |       10.5780  |\n",
            "|          |      4  |     0.8925  |   0.8280  |               |       13.1026  |\n",
            "|          |      5  |     0.9425  |   0.9021  |               |       15.6325  |\n",
            "|          |      6  |     0.9610  |   0.9224  |               |       18.1641  |\n",
            "|          |      7  |     0.9770  |   0.9315  |               |       20.6981  |\n",
            "|          |   eval  |     0.9770  |   0.9315  |       0.9315  |       20.8605  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     106  |      0  |     0.7380  |   0.6829  |               |        2.6797  |\n",
            "|          |      1  |     0.8030  |   0.6340  |               |        5.3726  |\n",
            "|          |      2  |     0.8530  |   0.8098  |               |        8.0619  |\n",
            "|          |      3  |     0.8730  |   0.8369  |               |       10.6119  |\n",
            "|          |      4  |     0.9095  |   0.8570  |               |       13.1455  |\n",
            "|          |      5  |     0.9355  |   0.9116  |               |       15.6982  |\n",
            "|          |      6  |     0.9600  |   0.9221  |               |       18.2328  |\n",
            "|          |      7  |     0.9770  |   0.9328  |               |       20.7678  |\n",
            "|          |   eval  |     0.9770  |   0.9328  |       0.9328  |       20.9291  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     107  |      0  |     0.7310  |   0.6406  |               |        2.6846  |\n",
            "|          |      1  |     0.7990  |   0.7209  |               |        5.3711  |\n",
            "|          |      2  |     0.8430  |   0.8331  |               |        8.0671  |\n",
            "|          |      3  |     0.8815  |   0.8308  |               |       10.6224  |\n",
            "|          |      4  |     0.9025  |   0.8626  |               |       13.1522  |\n",
            "|          |      5  |     0.9250  |   0.9056  |               |       15.6909  |\n",
            "|          |      6  |     0.9495  |   0.9227  |               |       18.2230  |\n",
            "|          |      7  |     0.9705  |   0.9311  |               |       20.7474  |\n",
            "|          |   eval  |     0.9705  |   0.9311  |       0.9311  |       20.9070  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     108  |      0  |     0.7175  |   0.6484  |               |        2.6816  |\n",
            "|          |      1  |     0.8070  |   0.7343  |               |        5.3807  |\n",
            "|          |      2  |     0.8545  |   0.8089  |               |        8.0763  |\n",
            "|          |      3  |     0.8765  |   0.8327  |               |       10.6303  |\n",
            "|          |      4  |     0.8980  |   0.8823  |               |       13.1597  |\n",
            "|          |      5  |     0.9290  |   0.9058  |               |       15.7142  |\n",
            "|          |      6  |     0.9465  |   0.9216  |               |       18.2452  |\n",
            "|          |      7  |     0.9755  |   0.9314  |               |       20.7980  |\n",
            "|          |   eval  |     0.9755  |   0.9314  |       0.9314  |       20.9609  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     109  |      0  |     0.7090  |   0.4471  |               |        2.6903  |\n",
            "|          |      1  |     0.8080  |   0.7846  |               |        5.3767  |\n",
            "|          |      2  |     0.8525  |   0.7866  |               |        8.0701  |\n",
            "|          |      3  |     0.8795  |   0.8013  |               |       10.6200  |\n",
            "|          |      4  |     0.9060  |   0.8729  |               |       13.1505  |\n",
            "|          |      5  |     0.9245  |   0.9035  |               |       15.7014  |\n",
            "|          |      6  |     0.9570  |   0.9240  |               |       18.2311  |\n",
            "|          |      7  |     0.9770  |   0.9327  |               |       20.7872  |\n",
            "|          |   eval  |     0.9770  |   0.9327  |       0.9327  |       20.9513  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     110  |      0  |     0.7310  |   0.5240  |               |        2.6814  |\n",
            "|          |      1  |     0.8195  |   0.7835  |               |        5.3789  |\n",
            "|          |      2  |     0.8500  |   0.8182  |               |        8.0858  |\n",
            "|          |      3  |     0.8735  |   0.8223  |               |       10.6412  |\n",
            "|          |      4  |     0.9120  |   0.8713  |               |       13.1694  |\n",
            "|          |      5  |     0.9340  |   0.9042  |               |       15.7252  |\n",
            "|          |      6  |     0.9590  |   0.9242  |               |       18.2582  |\n",
            "|          |      7  |     0.9765  |   0.9354  |               |       20.8126  |\n",
            "|          |   eval  |     0.9765  |   0.9354  |       0.9354  |       20.9768  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     111  |      0  |     0.7255  |   0.5473  |               |        2.6869  |\n",
            "|          |      1  |     0.8225  |   0.7760  |               |        5.3925  |\n",
            "|          |      2  |     0.8455  |   0.8087  |               |        8.0936  |\n",
            "|          |      3  |     0.8690  |   0.8263  |               |       10.6417  |\n",
            "|          |      4  |     0.9110  |   0.8800  |               |       13.1680  |\n",
            "|          |      5  |     0.9190  |   0.9036  |               |       15.7210  |\n",
            "|          |      6  |     0.9555  |   0.9223  |               |       18.2530  |\n",
            "|          |      7  |     0.9795  |   0.9316  |               |       20.7866  |\n",
            "|          |   eval  |     0.9795  |   0.9316  |       0.9316  |       20.9491  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     112  |      0  |     0.7365  |   0.6157  |               |        2.6796  |\n",
            "|          |      1  |     0.8350  |   0.7665  |               |        5.3793  |\n",
            "|          |      2  |     0.8525  |   0.8181  |               |        8.0799  |\n",
            "|          |      3  |     0.8745  |   0.8413  |               |       10.6342  |\n",
            "|          |      4  |     0.8915  |   0.8659  |               |       13.1659  |\n",
            "|          |      5  |     0.9355  |   0.9075  |               |       15.7203  |\n",
            "|          |      6  |     0.9515  |   0.9250  |               |       18.2556  |\n",
            "|          |      7  |     0.9705  |   0.9336  |               |       20.7827  |\n",
            "|          |   eval  |     0.9705  |   0.9336  |       0.9336  |       20.9459  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     113  |      0  |     0.7390  |   0.5652  |               |        2.6780  |\n",
            "|          |      1  |     0.8025  |   0.6455  |               |        5.3690  |\n",
            "|          |      2  |     0.8375  |   0.7660  |               |        8.0632  |\n",
            "|          |      3  |     0.8740  |   0.8032  |               |       10.6119  |\n",
            "|          |      4  |     0.8955  |   0.8792  |               |       13.1455  |\n",
            "|          |      5  |     0.9260  |   0.9046  |               |       15.6806  |\n",
            "|          |      6  |     0.9520  |   0.9204  |               |       18.2133  |\n",
            "|          |      7  |     0.9760  |   0.9311  |               |       20.7712  |\n",
            "|          |   eval  |     0.9760  |   0.9311  |       0.9311  |       20.9338  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     114  |      0  |     0.7300  |   0.6799  |               |        2.6758  |\n",
            "|          |      1  |     0.8155  |   0.7012  |               |        5.3703  |\n",
            "|          |      2  |     0.8460  |   0.7175  |               |        8.0617  |\n",
            "|          |      3  |     0.8805  |   0.8384  |               |       10.6100  |\n",
            "|          |      4  |     0.9120  |   0.8797  |               |       13.1416  |\n",
            "|          |      5  |     0.9425  |   0.9091  |               |       15.6940  |\n",
            "|          |      6  |     0.9525  |   0.9246  |               |       18.2261  |\n",
            "|          |      7  |     0.9760  |   0.9324  |               |       20.7634  |\n",
            "|          |   eval  |     0.9760  |   0.9324  |       0.9324  |       20.9256  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     115  |      0  |     0.7360  |   0.6637  |               |        2.6799  |\n",
            "|          |      1  |     0.8130  |   0.5423  |               |        5.3658  |\n",
            "|          |      2  |     0.8555  |   0.8196  |               |        8.0569  |\n",
            "|          |      3  |     0.8685  |   0.8063  |               |       10.6024  |\n",
            "|          |      4  |     0.9140  |   0.8808  |               |       13.1303  |\n",
            "|          |      5  |     0.9260  |   0.9011  |               |       15.6638  |\n",
            "|          |      6  |     0.9480  |   0.9220  |               |       18.1992  |\n",
            "|          |      7  |     0.9765  |   0.9309  |               |       20.7329  |\n",
            "|          |   eval  |     0.9765  |   0.9309  |       0.9309  |       20.8971  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     116  |      0  |     0.7420  |   0.7190  |               |        2.6691  |\n",
            "|          |      1  |     0.8270  |   0.6817  |               |        5.3602  |\n",
            "|          |      2  |     0.8460  |   0.7967  |               |        8.0515  |\n",
            "|          |      3  |     0.8770  |   0.8489  |               |       10.6003  |\n",
            "|          |      4  |     0.8985  |   0.8929  |               |       13.1355  |\n",
            "|          |      5  |     0.9300  |   0.8932  |               |       15.6747  |\n",
            "|          |      6  |     0.9520  |   0.9226  |               |       18.2063  |\n",
            "|          |      7  |     0.9755  |   0.9346  |               |       20.7337  |\n",
            "|          |   eval  |     0.9755  |   0.9346  |       0.9346  |       20.8972  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     117  |      0  |     0.7380  |   0.6040  |               |        2.6788  |\n",
            "|          |      1  |     0.8290  |   0.7665  |               |        5.3667  |\n",
            "|          |      2  |     0.8510  |   0.7977  |               |        8.0560  |\n",
            "|          |      3  |     0.8745  |   0.8761  |               |       10.5922  |\n",
            "|          |      4  |     0.8975  |   0.8069  |               |       13.1228  |\n",
            "|          |      5  |     0.9195  |   0.8754  |               |       15.6515  |\n",
            "|          |      6  |     0.9540  |   0.9217  |               |       18.1859  |\n",
            "|          |      7  |     0.9785  |   0.9326  |               |       20.7190  |\n",
            "|          |   eval  |     0.9785  |   0.9326  |       0.9326  |       20.8821  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     118  |      0  |     0.6980  |   0.5973  |               |        2.6700  |\n",
            "|          |      1  |     0.8190  |   0.7312  |               |        5.3680  |\n",
            "|          |      2  |     0.8445  |   0.7644  |               |        8.0638  |\n",
            "|          |      3  |     0.8765  |   0.8494  |               |       10.6089  |\n",
            "|          |      4  |     0.9070  |   0.8532  |               |       13.1387  |\n",
            "|          |      5  |     0.9335  |   0.9123  |               |       15.6912  |\n",
            "|          |      6  |     0.9515  |   0.9233  |               |       18.2250  |\n",
            "|          |      7  |     0.9770  |   0.9339  |               |       20.7595  |\n",
            "|          |   eval  |     0.9770  |   0.9339  |       0.9339  |       20.9223  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     119  |      0  |     0.7450  |   0.6640  |               |        2.6820  |\n",
            "|          |      1  |     0.7955  |   0.6770  |               |        5.3726  |\n",
            "|          |      2  |     0.8470  |   0.8194  |               |        8.0678  |\n",
            "|          |      3  |     0.8955  |   0.8594  |               |       10.6100  |\n",
            "|          |      4  |     0.9105  |   0.8831  |               |       13.1453  |\n",
            "|          |      5  |     0.9425  |   0.9026  |               |       15.6980  |\n",
            "|          |      6  |     0.9535  |   0.9232  |               |       18.2314  |\n",
            "|          |      7  |     0.9785  |   0.9315  |               |       20.7645  |\n",
            "|          |   eval  |     0.9785  |   0.9315  |       0.9315  |       20.9283  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     120  |      0  |     0.7220  |   0.5625  |               |        2.6730  |\n",
            "|          |      1  |     0.8165  |   0.7273  |               |        5.3747  |\n",
            "|          |      2  |     0.8460  |   0.7900  |               |        8.0685  |\n",
            "|          |      3  |     0.8785  |   0.8357  |               |       10.6167  |\n",
            "|          |      4  |     0.9095  |   0.8846  |               |       13.1496  |\n",
            "|          |      5  |     0.9265  |   0.8985  |               |       15.7011  |\n",
            "|          |      6  |     0.9525  |   0.9238  |               |       18.2360  |\n",
            "|          |      7  |     0.9785  |   0.9333  |               |       20.7862  |\n",
            "|          |   eval  |     0.9785  |   0.9333  |       0.9333  |       20.9504  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     121  |      0  |     0.7260  |   0.6732  |               |        2.6871  |\n",
            "|          |      1  |     0.8175  |   0.7462  |               |        5.3799  |\n",
            "|          |      2  |     0.8565  |   0.7968  |               |        8.0749  |\n",
            "|          |      3  |     0.8785  |   0.8445  |               |       10.6131  |\n",
            "|          |      4  |     0.9075  |   0.8679  |               |       13.1463  |\n",
            "|          |      5  |     0.9250  |   0.8895  |               |       15.6981  |\n",
            "|          |      6  |     0.9570  |   0.9152  |               |       18.2294  |\n",
            "|          |      7  |     0.9805  |   0.9297  |               |       20.7845  |\n",
            "|          |   eval  |     0.9805  |   0.9297  |       0.9297  |       20.9490  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     122  |      0  |     0.7270  |   0.5677  |               |        2.6914  |\n",
            "|          |      1  |     0.8145  |   0.6788  |               |        5.3860  |\n",
            "|          |      2  |     0.8530  |   0.7732  |               |        8.0817  |\n",
            "|          |      3  |     0.8940  |   0.8354  |               |       10.6340  |\n",
            "|          |      4  |     0.9060  |   0.8785  |               |       13.1731  |\n",
            "|          |      5  |     0.9355  |   0.8921  |               |       15.7283  |\n",
            "|          |      6  |     0.9545  |   0.9183  |               |       18.2452  |\n",
            "|          |      7  |     0.9720  |   0.9307  |               |       20.7965  |\n",
            "|          |   eval  |     0.9720  |   0.9307  |       0.9307  |       20.9594  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     123  |      0  |     0.7080  |   0.7363  |               |        2.6700  |\n",
            "|          |      1  |     0.8020  |   0.7780  |               |        5.3632  |\n",
            "|          |      2  |     0.8520  |   0.8381  |               |        8.0506  |\n",
            "|          |      3  |     0.8875  |   0.8311  |               |       10.5803  |\n",
            "|          |      4  |     0.9135  |   0.8856  |               |       13.1101  |\n",
            "|          |      5  |     0.9325  |   0.9011  |               |       15.6639  |\n",
            "|          |      6  |     0.9610  |   0.9267  |               |       18.1787  |\n",
            "|          |      7  |     0.9695  |   0.9339  |               |       20.6932  |\n",
            "|          |   eval  |     0.9695  |   0.9339  |       0.9339  |       20.8574  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     124  |      0  |     0.7265  |   0.5990  |               |        2.6728  |\n",
            "|          |      1  |     0.8070  |   0.7493  |               |        5.3618  |\n",
            "|          |      2  |     0.8655  |   0.7809  |               |        8.0473  |\n",
            "|          |      3  |     0.8855  |   0.8580  |               |       10.5888  |\n",
            "|          |      4  |     0.9170  |   0.8881  |               |       13.1158  |\n",
            "|          |      5  |     0.9330  |   0.9060  |               |       15.6347  |\n",
            "|          |      6  |     0.9530  |   0.9205  |               |       18.1682  |\n",
            "|          |      7  |     0.9745  |   0.9318  |               |       20.6825  |\n",
            "|          |   eval  |     0.9745  |   0.9318  |       0.9318  |       20.8446  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     125  |      0  |     0.7415  |   0.5888  |               |        2.6792  |\n",
            "|          |      1  |     0.8140  |   0.7457  |               |        5.3665  |\n",
            "|          |      2  |     0.8570  |   0.8122  |               |        8.0607  |\n",
            "|          |      3  |     0.8830  |   0.7599  |               |       10.5899  |\n",
            "|          |      4  |     0.9085  |   0.8560  |               |       13.1218  |\n",
            "|          |      5  |     0.9260  |   0.9082  |               |       15.6583  |\n",
            "|          |      6  |     0.9580  |   0.9205  |               |       18.1955  |\n",
            "|          |      7  |     0.9785  |   0.9339  |               |       20.7504  |\n",
            "|          |   eval  |     0.9785  |   0.9339  |       0.9339  |       20.9145  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     126  |      0  |     0.7235  |   0.6483  |               |        2.6727  |\n",
            "|          |      1  |     0.8045  |   0.7534  |               |        5.3639  |\n",
            "|          |      2  |     0.8475  |   0.8069  |               |        8.0524  |\n",
            "|          |      3  |     0.8855  |   0.8233  |               |       10.5944  |\n",
            "|          |      4  |     0.8985  |   0.8844  |               |       13.1271  |\n",
            "|          |      5  |     0.9210  |   0.9009  |               |       15.6587  |\n",
            "|          |      6  |     0.9470  |   0.9172  |               |       18.1929  |\n",
            "|          |      7  |     0.9800  |   0.9311  |               |       20.7264  |\n",
            "|          |   eval  |     0.9800  |   0.9311  |       0.9311  |       20.8870  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     127  |      0  |     0.7370  |   0.6454  |               |        2.6797  |\n",
            "|          |      1  |     0.8175  |   0.7794  |               |        5.3708  |\n",
            "|          |      2  |     0.8530  |   0.8103  |               |        8.0544  |\n",
            "|          |      3  |     0.8795  |   0.8348  |               |       10.5840  |\n",
            "|          |      4  |     0.9035  |   0.8731  |               |       13.1106  |\n",
            "|          |      5  |     0.9300  |   0.8973  |               |       15.6429  |\n",
            "|          |      6  |     0.9615  |   0.9213  |               |       18.1743  |\n",
            "|          |      7  |     0.9810  |   0.9314  |               |       20.7124  |\n",
            "|          |   eval  |     0.9810  |   0.9314  |       0.9314  |       20.8765  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     128  |      0  |     0.7275  |   0.6584  |               |        2.6828  |\n",
            "|          |      1  |     0.8090  |   0.6952  |               |        5.3674  |\n",
            "|          |      2  |     0.8495  |   0.7526  |               |        8.0553  |\n",
            "|          |      3  |     0.8895  |   0.8380  |               |       10.6062  |\n",
            "|          |      4  |     0.9050  |   0.8898  |               |       13.1434  |\n",
            "|          |      5  |     0.9350  |   0.9064  |               |       15.6802  |\n",
            "|          |      6  |     0.9560  |   0.9193  |               |       18.2175  |\n",
            "|          |      7  |     0.9815  |   0.9310  |               |       20.7491  |\n",
            "|          |   eval  |     0.9815  |   0.9310  |       0.9310  |       20.9139  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     129  |      0  |     0.7205  |   0.6517  |               |        2.6680  |\n",
            "|          |      1  |     0.8115  |   0.7713  |               |        5.3663  |\n",
            "|          |      2  |     0.8550  |   0.8138  |               |        8.0611  |\n",
            "|          |      3  |     0.8835  |   0.8621  |               |       10.6069  |\n",
            "|          |      4  |     0.9120  |   0.8761  |               |       13.1383  |\n",
            "|          |      5  |     0.9325  |   0.9065  |               |       15.6899  |\n",
            "|          |      6  |     0.9505  |   0.9217  |               |       18.2234  |\n",
            "|          |      7  |     0.9735  |   0.9323  |               |       20.7556  |\n",
            "|          |   eval  |     0.9735  |   0.9323  |       0.9323  |       20.9197  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     130  |      0  |     0.7115  |   0.5412  |               |        2.6672  |\n",
            "|          |      1  |     0.8290  |   0.6929  |               |        5.3598  |\n",
            "|          |      2  |     0.8500  |   0.8280  |               |        8.0518  |\n",
            "|          |      3  |     0.8805  |   0.8017  |               |       10.5848  |\n",
            "|          |      4  |     0.9060  |   0.8927  |               |       13.1194  |\n",
            "|          |      5  |     0.9385  |   0.8907  |               |       15.6730  |\n",
            "|          |      6  |     0.9535  |   0.9223  |               |       18.2059  |\n",
            "|          |      7  |     0.9800  |   0.9304  |               |       20.7600  |\n",
            "|          |   eval  |     0.9800  |   0.9304  |       0.9304  |       20.9232  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     131  |      0  |     0.7230  |   0.5453  |               |        2.6857  |\n",
            "|          |      1  |     0.8060  |   0.7319  |               |        5.3823  |\n",
            "|          |      2  |     0.8465  |   0.7705  |               |        8.0773  |\n",
            "|          |      3  |     0.8790  |   0.8217  |               |       10.6196  |\n",
            "|          |      4  |     0.9200  |   0.8903  |               |       13.1540  |\n",
            "|          |      5  |     0.9270  |   0.9094  |               |       15.6854  |\n",
            "|          |      6  |     0.9575  |   0.9181  |               |       18.2239  |\n",
            "|          |      7  |     0.9770  |   0.9319  |               |       20.7579  |\n",
            "|          |   eval  |     0.9770  |   0.9319  |       0.9319  |       20.9209  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     132  |      0  |     0.7220  |   0.6263  |               |        2.6799  |\n",
            "|          |      1  |     0.8045  |   0.7778  |               |        5.3692  |\n",
            "|          |      2  |     0.8555  |   0.7986  |               |        8.0633  |\n",
            "|          |      3  |     0.8960  |   0.8474  |               |       10.6173  |\n",
            "|          |      4  |     0.9065  |   0.8797  |               |       13.1699  |\n",
            "|          |      5  |     0.9285  |   0.9051  |               |       15.6985  |\n",
            "|          |      6  |     0.9580  |   0.9257  |               |       18.2328  |\n",
            "|          |      7  |     0.9780  |   0.9327  |               |       20.7672  |\n",
            "|          |   eval  |     0.9780  |   0.9327  |       0.9327  |       20.9288  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     133  |      0  |     0.7575  |   0.6868  |               |        2.6838  |\n",
            "|          |      1  |     0.8000  |   0.7272  |               |        5.3739  |\n",
            "|          |      2  |     0.8605  |   0.7407  |               |        8.0681  |\n",
            "|          |      3  |     0.8840  |   0.8638  |               |       10.6134  |\n",
            "|          |      4  |     0.8810  |   0.8671  |               |       13.1457  |\n",
            "|          |      5  |     0.9235  |   0.9064  |               |       15.7018  |\n",
            "|          |      6  |     0.9480  |   0.9236  |               |       18.2294  |\n",
            "|          |      7  |     0.9805  |   0.9296  |               |       20.7489  |\n",
            "|          |   eval  |     0.9805  |   0.9296  |       0.9296  |       20.9105  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     134  |      0  |     0.7220  |   0.6513  |               |        2.6694  |\n",
            "|          |      1  |     0.8220  |   0.7720  |               |        5.3604  |\n",
            "|          |      2  |     0.8530  |   0.8220  |               |        8.0477  |\n",
            "|          |      3  |     0.8855  |   0.8234  |               |       10.5765  |\n",
            "|          |      4  |     0.9005  |   0.8894  |               |       13.1141  |\n",
            "|          |      5  |     0.9395  |   0.9074  |               |       15.6310  |\n",
            "|          |      6  |     0.9580  |   0.9217  |               |       18.1459  |\n",
            "|          |      7  |     0.9740  |   0.9329  |               |       20.6607  |\n",
            "|          |   eval  |     0.9740  |   0.9329  |       0.9329  |       20.8237  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     135  |      0  |     0.7245  |   0.6282  |               |        2.6624  |\n",
            "|          |      1  |     0.8335  |   0.7115  |               |        5.3423  |\n",
            "|          |      2  |     0.8520  |   0.7677  |               |        8.0205  |\n",
            "|          |      3  |     0.8835  |   0.8454  |               |       10.5464  |\n",
            "|          |      4  |     0.9030  |   0.8625  |               |       13.0590  |\n",
            "|          |      5  |     0.9415  |   0.9020  |               |       15.5686  |\n",
            "|          |      6  |     0.9550  |   0.9242  |               |       18.0821  |\n",
            "|          |      7  |     0.9785  |   0.9325  |               |       20.5838  |\n",
            "|          |   eval  |     0.9785  |   0.9325  |       0.9325  |       20.7446  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     136  |      0  |     0.7190  |   0.6000  |               |        2.6551  |\n",
            "|          |      1  |     0.8120  |   0.6684  |               |        5.3313  |\n",
            "|          |      2  |     0.8500  |   0.7169  |               |        8.0105  |\n",
            "|          |      3  |     0.8715  |   0.8500  |               |       10.5323  |\n",
            "|          |      4  |     0.9195  |   0.8644  |               |       13.0493  |\n",
            "|          |      5  |     0.9335  |   0.9079  |               |       15.5599  |\n",
            "|          |      6  |     0.9540  |   0.9214  |               |       18.0594  |\n",
            "|          |      7  |     0.9750  |   0.9324  |               |       20.5718  |\n",
            "|          |   eval  |     0.9750  |   0.9324  |       0.9324  |       20.7325  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     137  |      0  |     0.7285  |   0.6033  |               |        2.6587  |\n",
            "|          |      1  |     0.8220  |   0.7131  |               |        5.3329  |\n",
            "|          |      2  |     0.8405  |   0.7729  |               |        8.0135  |\n",
            "|          |      3  |     0.8805  |   0.8654  |               |       10.5280  |\n",
            "|          |      4  |     0.9035  |   0.8613  |               |       13.0366  |\n",
            "|          |      5  |     0.9315  |   0.8988  |               |       15.5395  |\n",
            "|          |      6  |     0.9580  |   0.9265  |               |       18.0512  |\n",
            "|          |      7  |     0.9785  |   0.9314  |               |       20.5532  |\n",
            "|          |   eval  |     0.9785  |   0.9314  |       0.9314  |       20.7143  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     138  |      0  |     0.7285  |   0.6295  |               |        2.6608  |\n",
            "|          |      1  |     0.8110  |   0.6776  |               |        5.3331  |\n",
            "|          |      2  |     0.8600  |   0.6400  |               |        8.0092  |\n",
            "|          |      3  |     0.8750  |   0.8360  |               |       10.5230  |\n",
            "|          |      4  |     0.9065  |   0.8934  |               |       13.0303  |\n",
            "|          |      5  |     0.9230  |   0.9031  |               |       15.5469  |\n",
            "|          |      6  |     0.9550  |   0.9277  |               |       18.0586  |\n",
            "|          |      7  |     0.9730  |   0.9350  |               |       20.5649  |\n",
            "|          |   eval  |     0.9730  |   0.9350  |       0.9350  |       20.7268  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     139  |      0  |     0.7430  |   0.6564  |               |        2.6500  |\n",
            "|          |      1  |     0.8250  |   0.6602  |               |        5.3375  |\n",
            "|          |      2  |     0.8400  |   0.8219  |               |        8.0228  |\n",
            "|          |      3  |     0.8920  |   0.8556  |               |       10.5469  |\n",
            "|          |      4  |     0.9035  |   0.8552  |               |       13.0611  |\n",
            "|          |      5  |     0.9160  |   0.8984  |               |       15.5767  |\n",
            "|          |      6  |     0.9595  |   0.9237  |               |       18.0881  |\n",
            "|          |      7  |     0.9785  |   0.9301  |               |       20.6030  |\n",
            "|          |   eval  |     0.9785  |   0.9301  |       0.9301  |       20.7647  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     140  |      0  |     0.7170  |   0.6205  |               |        2.6687  |\n",
            "|          |      1  |     0.8130  |   0.7606  |               |        5.3406  |\n",
            "|          |      2  |     0.8535  |   0.7909  |               |        8.0293  |\n",
            "|          |      3  |     0.8760  |   0.8296  |               |       10.5837  |\n",
            "|          |      4  |     0.9150  |   0.8693  |               |       13.0982  |\n",
            "|          |      5  |     0.9275  |   0.9012  |               |       15.6382  |\n",
            "|          |      6  |     0.9590  |   0.9173  |               |       18.1554  |\n",
            "|          |      7  |     0.9725  |   0.9302  |               |       20.6745  |\n",
            "|          |   eval  |     0.9725  |   0.9302  |       0.9302  |       20.8373  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     141  |      0  |     0.7165  |   0.4234  |               |        2.6651  |\n",
            "|          |      1  |     0.8260  |   0.7413  |               |        5.3407  |\n",
            "|          |      2  |     0.8465  |   0.8025  |               |        8.0273  |\n",
            "|          |      3  |     0.8715  |   0.7698  |               |       10.5634  |\n",
            "|          |      4  |     0.9010  |   0.8763  |               |       13.0985  |\n",
            "|          |      5  |     0.9315  |   0.9013  |               |       15.6300  |\n",
            "|          |      6  |     0.9545  |   0.9206  |               |       18.1629  |\n",
            "|          |      7  |     0.9730  |   0.9308  |               |       20.6999  |\n",
            "|          |   eval  |     0.9730  |   0.9308  |       0.9308  |       20.8639  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     142  |      0  |     0.7410  |   0.6045  |               |        2.6791  |\n",
            "|          |      1  |     0.8180  |   0.7817  |               |        5.3619  |\n",
            "|          |      2  |     0.8435  |   0.8041  |               |        8.0472  |\n",
            "|          |      3  |     0.8595  |   0.8437  |               |       10.5782  |\n",
            "|          |      4  |     0.9260  |   0.8568  |               |       13.1128  |\n",
            "|          |      5  |     0.9485  |   0.8881  |               |       15.6468  |\n",
            "|          |      6  |     0.9560  |   0.9257  |               |       18.1635  |\n",
            "|          |      7  |     0.9735  |   0.9330  |               |       20.6969  |\n",
            "|          |   eval  |     0.9735  |   0.9330  |       0.9330  |       20.8584  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     143  |      0  |     0.7145  |   0.4028  |               |        2.6658  |\n",
            "|          |      1  |     0.8010  |   0.7389  |               |        5.3533  |\n",
            "|          |      2  |     0.8545  |   0.7118  |               |        8.0390  |\n",
            "|          |      3  |     0.8635  |   0.8017  |               |       10.5756  |\n",
            "|          |      4  |     0.9080  |   0.8872  |               |       13.0956  |\n",
            "|          |      5  |     0.9300  |   0.9069  |               |       15.6266  |\n",
            "|          |      6  |     0.9600  |   0.9191  |               |       18.1471  |\n",
            "|          |      7  |     0.9725  |   0.9311  |               |       20.6712  |\n",
            "|          |   eval  |     0.9725  |   0.9311  |       0.9311  |       20.8324  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     144  |      0  |     0.7365  |   0.6710  |               |        2.6676  |\n",
            "|          |      1  |     0.8170  |   0.6140  |               |        5.3535  |\n",
            "|          |      2  |     0.8370  |   0.7952  |               |        8.0393  |\n",
            "|          |      3  |     0.8690  |   0.8488  |               |       10.5808  |\n",
            "|          |      4  |     0.9030  |   0.8644  |               |       13.1160  |\n",
            "|          |      5  |     0.9270  |   0.8971  |               |       15.6478  |\n",
            "|          |      6  |     0.9615  |   0.9240  |               |       18.1656  |\n",
            "|          |      7  |     0.9730  |   0.9320  |               |       20.6975  |\n",
            "|          |   eval  |     0.9730  |   0.9320  |       0.9320  |       20.8581  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     145  |      0  |     0.7520  |   0.5819  |               |        2.6715  |\n",
            "|          |      1  |     0.8235  |   0.7205  |               |        5.3624  |\n",
            "|          |      2  |     0.8710  |   0.8071  |               |        8.0491  |\n",
            "|          |      3  |     0.8745  |   0.8439  |               |       10.5889  |\n",
            "|          |      4  |     0.9105  |   0.8798  |               |       13.1209  |\n",
            "|          |      5  |     0.9310  |   0.8985  |               |       15.6542  |\n",
            "|          |      6  |     0.9620  |   0.9216  |               |       18.1895  |\n",
            "|          |      7  |     0.9765  |   0.9299  |               |       20.7216  |\n",
            "|          |   eval  |     0.9765  |   0.9299  |       0.9299  |       20.8840  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     146  |      0  |     0.7395  |   0.6891  |               |        2.6755  |\n",
            "|          |      1  |     0.8285  |   0.7779  |               |        5.3709  |\n",
            "|          |      2  |     0.8495  |   0.8278  |               |        8.0631  |\n",
            "|          |      3  |     0.8940  |   0.8416  |               |       10.5861  |\n",
            "|          |      4  |     0.9085  |   0.8779  |               |       13.1200  |\n",
            "|          |      5  |     0.9265  |   0.9010  |               |       15.6577  |\n",
            "|          |      6  |     0.9550  |   0.9231  |               |       18.1950  |\n",
            "|          |      7  |     0.9760  |   0.9317  |               |       20.7311  |\n",
            "|          |   eval  |     0.9760  |   0.9317  |       0.9317  |       20.8940  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     147  |      0  |     0.7115  |   0.6414  |               |        2.6829  |\n",
            "|          |      1  |     0.8035  |   0.7380  |               |        5.3764  |\n",
            "|          |      2  |     0.8615  |   0.7986  |               |        8.0664  |\n",
            "|          |      3  |     0.8775  |   0.8542  |               |       10.6175  |\n",
            "|          |      4  |     0.9135  |   0.8744  |               |       13.1488  |\n",
            "|          |      5  |     0.9285  |   0.9060  |               |       15.6822  |\n",
            "|          |      6  |     0.9530  |   0.9247  |               |       18.2133  |\n",
            "|          |      7  |     0.9735  |   0.9308  |               |       20.7650  |\n",
            "|          |   eval  |     0.9735  |   0.9308  |       0.9308  |       20.9300  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     148  |      0  |     0.7530  |   0.6844  |               |        2.6859  |\n",
            "|          |      1  |     0.8370  |   0.7148  |               |        5.3741  |\n",
            "|          |      2  |     0.8470  |   0.7874  |               |        8.0640  |\n",
            "|          |      3  |     0.8865  |   0.8241  |               |       10.6030  |\n",
            "|          |      4  |     0.9060  |   0.8885  |               |       13.1352  |\n",
            "|          |      5  |     0.9325  |   0.9076  |               |       15.6898  |\n",
            "|          |      6  |     0.9555  |   0.9192  |               |       18.2189  |\n",
            "|          |      7  |     0.9815  |   0.9313  |               |       20.7535  |\n",
            "|          |   eval  |     0.9815  |   0.9313  |       0.9313  |       20.9167  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     149  |      0  |     0.7420  |   0.6603  |               |        2.6827  |\n",
            "|          |      1  |     0.8275  |   0.7211  |               |        5.3755  |\n",
            "|          |      2  |     0.8550  |   0.7712  |               |        8.0695  |\n",
            "|          |      3  |     0.8720  |   0.8548  |               |       10.6192  |\n",
            "|          |      4  |     0.9035  |   0.8777  |               |       13.1530  |\n",
            "|          |      5  |     0.9425  |   0.9016  |               |       15.7082  |\n",
            "|          |      6  |     0.9600  |   0.9232  |               |       18.2427  |\n",
            "|          |      7  |     0.9795  |   0.9308  |               |       20.8016  |\n",
            "|          |   eval  |     0.9795  |   0.9308  |       0.9308  |       20.9647  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     150  |      0  |     0.7265  |   0.5989  |               |        2.6924  |\n",
            "|          |      1  |     0.7990  |   0.7420  |               |        5.3857  |\n",
            "|          |      2  |     0.8535  |   0.8045  |               |        8.0911  |\n",
            "|          |      3  |     0.8750  |   0.8517  |               |       10.6287  |\n",
            "|          |      4  |     0.8930  |   0.8743  |               |       13.1589  |\n",
            "|          |      5  |     0.9320  |   0.8989  |               |       15.7112  |\n",
            "|          |      6  |     0.9560  |   0.9183  |               |       18.2416  |\n",
            "|          |      7  |     0.9725  |   0.9311  |               |       20.7956  |\n",
            "|          |   eval  |     0.9725  |   0.9311  |       0.9311  |       20.9587  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     151  |      0  |     0.7270  |   0.5714  |               |        2.6906  |\n",
            "|          |      1  |     0.8185  |   0.7571  |               |        5.3875  |\n",
            "|          |      2  |     0.8325  |   0.8057  |               |        8.0837  |\n",
            "|          |      3  |     0.8820  |   0.8404  |               |       10.6295  |\n",
            "|          |      4  |     0.9015  |   0.8823  |               |       13.1571  |\n",
            "|          |      5  |     0.9345  |   0.9076  |               |       15.7063  |\n",
            "|          |      6  |     0.9555  |   0.9245  |               |       18.2404  |\n",
            "|          |      7  |     0.9760  |   0.9329  |               |       20.7952  |\n",
            "|          |   eval  |     0.9760  |   0.9329  |       0.9329  |       20.9577  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     152  |      0  |     0.7065  |   0.5667  |               |        2.6734  |\n",
            "|          |      1  |     0.8215  |   0.7240  |               |        5.3697  |\n",
            "|          |      2  |     0.8475  |   0.7913  |               |        8.0660  |\n",
            "|          |      3  |     0.8755  |   0.8528  |               |       10.6030  |\n",
            "|          |      4  |     0.9075  |   0.8797  |               |       13.1543  |\n",
            "|          |      5  |     0.9340  |   0.9029  |               |       15.6951  |\n",
            "|          |      6  |     0.9585  |   0.9195  |               |       18.2291  |\n",
            "|          |      7  |     0.9790  |   0.9300  |               |       20.7618  |\n",
            "|          |   eval  |     0.9790  |   0.9300  |       0.9300  |       20.9240  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     153  |      0  |     0.7465  |   0.6319  |               |        2.6816  |\n",
            "|          |      1  |     0.8135  |   0.7131  |               |        5.3700  |\n",
            "|          |      2  |     0.8590  |   0.8079  |               |        8.0613  |\n",
            "|          |      3  |     0.8880  |   0.8439  |               |       10.6049  |\n",
            "|          |      4  |     0.9030  |   0.8589  |               |       13.1339  |\n",
            "|          |      5  |     0.9320  |   0.9094  |               |       15.6824  |\n",
            "|          |      6  |     0.9550  |   0.9249  |               |       18.2158  |\n",
            "|          |      7  |     0.9780  |   0.9327  |               |       20.7682  |\n",
            "|          |   eval  |     0.9780  |   0.9327  |       0.9327  |       20.9322  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     154  |      0  |     0.7385  |   0.4958  |               |        2.6774  |\n",
            "|          |      1  |     0.8090  |   0.6230  |               |        5.3757  |\n",
            "|          |      2  |     0.8515  |   0.7547  |               |        8.0709  |\n",
            "|          |      3  |     0.8885  |   0.8475  |               |       10.6137  |\n",
            "|          |      4  |     0.9030  |   0.8509  |               |       13.1454  |\n",
            "|          |      5  |     0.9315  |   0.8729  |               |       15.6996  |\n",
            "|          |      6  |     0.9555  |   0.9271  |               |       18.2309  |\n",
            "|          |      7  |     0.9750  |   0.9334  |               |       20.7666  |\n",
            "|          |   eval  |     0.9750  |   0.9334  |       0.9334  |       20.9307  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     155  |      0  |     0.7425  |   0.5424  |               |        2.6869  |\n",
            "|          |      1  |     0.7910  |   0.6791  |               |        5.3817  |\n",
            "|          |      2  |     0.8655  |   0.7500  |               |        8.0782  |\n",
            "|          |      3  |     0.8775  |   0.8518  |               |       10.6366  |\n",
            "|          |      4  |     0.9070  |   0.8575  |               |       13.1719  |\n",
            "|          |      5  |     0.9345  |   0.8968  |               |       15.7286  |\n",
            "|          |      6  |     0.9520  |   0.9162  |               |       18.2620  |\n",
            "|          |      7  |     0.9745  |   0.9319  |               |       20.7990  |\n",
            "|          |   eval  |     0.9745  |   0.9319  |       0.9319  |       20.9612  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     156  |      0  |     0.7240  |   0.5726  |               |        2.6813  |\n",
            "|          |      1  |     0.8075  |   0.7037  |               |        5.3701  |\n",
            "|          |      2  |     0.8550  |   0.7534  |               |        8.0616  |\n",
            "|          |      3  |     0.8850  |   0.8505  |               |       10.6035  |\n",
            "|          |      4  |     0.9010  |   0.8753  |               |       13.1375  |\n",
            "|          |      5  |     0.9230  |   0.8983  |               |       15.6929  |\n",
            "|          |      6  |     0.9580  |   0.9250  |               |       18.2236  |\n",
            "|          |      7  |     0.9790  |   0.9314  |               |       20.7561  |\n",
            "|          |   eval  |     0.9790  |   0.9314  |       0.9314  |       20.9200  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     157  |      0  |     0.7685  |   0.6537  |               |        2.6725  |\n",
            "|          |      1  |     0.8380  |   0.7349  |               |        5.3779  |\n",
            "|          |      2  |     0.8400  |   0.7837  |               |        8.0790  |\n",
            "|          |      3  |     0.8810  |   0.8327  |               |       10.6282  |\n",
            "|          |      4  |     0.9000  |   0.8863  |               |       13.1559  |\n",
            "|          |      5  |     0.9165  |   0.8952  |               |       15.7082  |\n",
            "|          |      6  |     0.9595  |   0.9189  |               |       18.2397  |\n",
            "|          |      7  |     0.9760  |   0.9315  |               |       20.7738  |\n",
            "|          |   eval  |     0.9760  |   0.9315  |       0.9315  |       20.9366  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     158  |      0  |     0.7065  |   0.5671  |               |        2.6856  |\n",
            "|          |      1  |     0.8110  |   0.7544  |               |        5.3769  |\n",
            "|          |      2  |     0.8495  |   0.8192  |               |        8.0691  |\n",
            "|          |      3  |     0.8850  |   0.7899  |               |       10.6157  |\n",
            "|          |      4  |     0.9040  |   0.8687  |               |       13.1467  |\n",
            "|          |      5  |     0.9215  |   0.9016  |               |       15.7071  |\n",
            "|          |      6  |     0.9555  |   0.9203  |               |       18.2426  |\n",
            "|          |      7  |     0.9720  |   0.9333  |               |       20.7788  |\n",
            "|          |   eval  |     0.9720  |   0.9333  |       0.9333  |       20.9415  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     159  |      0  |     0.7375  |   0.6899  |               |        2.6800  |\n",
            "|          |      1  |     0.8115  |   0.7171  |               |        5.3834  |\n",
            "|          |      2  |     0.8635  |   0.7523  |               |        8.0766  |\n",
            "|          |      3  |     0.8805  |   0.8596  |               |       10.6296  |\n",
            "|          |      4  |     0.8940  |   0.8760  |               |       13.1579  |\n",
            "|          |      5  |     0.9185  |   0.9045  |               |       15.7115  |\n",
            "|          |      6  |     0.9540  |   0.9239  |               |       18.2610  |\n",
            "|          |      7  |     0.9825  |   0.9298  |               |       20.7972  |\n",
            "|          |   eval  |     0.9825  |   0.9298  |       0.9298  |       20.9603  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     160  |      0  |     0.6830  |   0.5791  |               |        2.6839  |\n",
            "|          |      1  |     0.8330  |   0.7976  |               |        5.3853  |\n",
            "|          |      2  |     0.8610  |   0.7861  |               |        8.0910  |\n",
            "|          |      3  |     0.8940  |   0.8571  |               |       10.6254  |\n",
            "|          |      4  |     0.9070  |   0.8726  |               |       13.1539  |\n",
            "|          |      5  |     0.9260  |   0.9001  |               |       15.7069  |\n",
            "|          |      6  |     0.9620  |   0.9160  |               |       18.2383  |\n",
            "|          |      7  |     0.9775  |   0.9307  |               |       20.7909  |\n",
            "|          |   eval  |     0.9775  |   0.9307  |       0.9307  |       20.9538  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     161  |      0  |     0.7045  |   0.6401  |               |        2.6848  |\n",
            "|          |      1  |     0.8165  |   0.7684  |               |        5.3840  |\n",
            "|          |      2  |     0.8585  |   0.7938  |               |        8.0887  |\n",
            "|          |      3  |     0.8760  |   0.8335  |               |       10.6381  |\n",
            "|          |      4  |     0.9035  |   0.8678  |               |       13.1723  |\n",
            "|          |      5  |     0.9385  |   0.8960  |               |       15.7276  |\n",
            "|          |      6  |     0.9595  |   0.9244  |               |       18.2615  |\n",
            "|          |      7  |     0.9765  |   0.9318  |               |       20.8165  |\n",
            "|          |   eval  |     0.9765  |   0.9318  |       0.9318  |       20.9798  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     162  |      0  |     0.7170  |   0.6984  |               |        2.6887  |\n",
            "|          |      1  |     0.8160  |   0.7506  |               |        5.3775  |\n",
            "|          |      2  |     0.8335  |   0.7851  |               |        8.0754  |\n",
            "|          |      3  |     0.8865  |   0.8361  |               |       10.6245  |\n",
            "|          |      4  |     0.9050  |   0.8653  |               |       13.1560  |\n",
            "|          |      5  |     0.9250  |   0.9096  |               |       15.7082  |\n",
            "|          |      6  |     0.9525  |   0.9206  |               |       18.2400  |\n",
            "|          |      7  |     0.9810  |   0.9289  |               |       20.7742  |\n",
            "|          |   eval  |     0.9810  |   0.9289  |       0.9289  |       20.9367  |\n",
            "---------------------------------------------------------------------------------\n",
            "|     163  |      0  |     0.7220  |   0.6282  |               |        2.6830  |\n",
            "|          |      1  |     0.8130  |   0.7635  |               |        5.3813  |\n",
            "|          |      2  |     0.8465  |   0.7059  |               |        8.0810  |\n",
            "|          |      3  |     0.8840  |   0.8557  |               |       10.6329  |\n",
            "|          |      4  |     0.9040  |   0.8780  |               |       13.1602  |\n",
            "|          |      5  |     0.9275  |   0.9045  |               |       15.6929  |\n",
            "|          |      6  |     0.9535  |   0.9258  |               |       18.2235  |\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-199983949.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging_columns_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'warmup'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean: %.4f    Std: %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2716417740.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(run, model)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhiten_bias_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mwhiten_bias_train_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_lr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mwhiten_bias_train_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "questions i have :\n",
        "1. how exactly do we make sure that we don't run OOM on cuda, how do different dtypes used while training (bfloat16, fp32, fp16, mxfp4, int4, int8)\n",
        "   impact the memory and what exactly goes / loads on memory while using torch.compile()\n",
        "2. using reduction=\"mean\" (default torch behaviour), or reduction=\"sum\", how do we correctly log val and train losses in both, is there a generalized way to do\n",
        "   how does the last batch_size affect the logging if the number of samples is not a multiple of batch_size ?\n",
        "3. why do we go with batch_sizes which are normally are a multiple of 16 (32, 128, 512 ... ?), is this related to warps in gpus ?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Ab-AGYWJnfa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t9BHb9A0xomC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}